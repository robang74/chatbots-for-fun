<div id="firstdiv" created=":EN" style="max-width: 800px; margin: auto; white-space: pre-wrap; text-align: justify;">
<style>#printlink { display: inline; } @page { size: legal; margin: 0.50in 13.88mm 0.50in 13.88mm; zoom: 100%; } @media print { html { zoom: 100%; } }</style>

<!-- div align="center"><img class="wbsketch darkinv" src="img/" width="800"><br></div //-->

## L'AI è un game-changer perché è onesta

- **1st draft** - Articolo scritto a partire da un [post](https://www.linkedin.com/posts/robertofoglietta_quattro-prescrizioni-di-tac-e-risonanze-activity-7342726841666867200-tHqK) pubblicato su LinkedIn lo stesso giorno

---

### Introduzione

La domanda in generale può essere difficile da spiegare ma questo caso lo mostra in modo eclatante il perché l'AI è un game-changer e lo è in modo particolare quando è usata in modo corretto. La risposta è contenuta tutta quanti in questa apparentemente banale frase:

> In una seconda fase, un gruppo di esperti (radiologi e medici clinici) ha validato i risultati dell’algoritmo tramite revisione manuale a campione.

Per comprendere meglio occorre porsi nel caso in cui l'AI non sia inclusa nello scenario (oppure usata da incompetenti) e quindi avremmo certamente i seguenti fattori sistemici:

1. una mole immensa di lavoro che sarebbe anti-economico svolgere

2. anche se fosse svolta sarebbe data da eseguire alla stessa categoria

Quindi radiologi e clinici, avrebbero giudicato inappropriati solo gli outlier, pochi e palesemente inappropriati, mentre avrebbero usato i watermark di categoria per confermare il lavoro dei colleghi: cane non mangia cane.

L'AI è molto veloce, ignora i watermark, però deve essere verificata a campione (#1). Coloro che lo fanno (#2) sanno che l'AI è neutrale e anche loro debbono esserlo. Ergo l'AI passa il test anche in doppio cieco, oppure è stata usata o istruita male.

---

### Alcuni dati dello studio

- 17.000 prescrizioni

- 38,9% appropriate

- 43% inappropriata

Tolleranza massima stimata 3%, se il 40% nel titolo è un dato emergente dallo studio come il minore spreco che è ragionevolmente è possibile ridurre, piuttosto che una semplificazione di chi ha deciso il titolo.

Ma allora doveva essere 60% piuttosto, visto che meno del 40% risultano appropriate oppure nel titolo doveva essere scritto «utile» ma allora manca un "solo" nella frase. Ecco, questo invece è ciò che le AI non sanno fare (o lo fanno molto peggio degli umani) fare speculazioni e decidere quale sia la cosa più probabile.

Il valore 38.9% è preciso alla prima cifra decimale, senza ulteriori informazioni significherebbe che la precisione è 0.1% ma la tolleranza massima può essere diversa, tipo 38.9% ± 0.4%.

---

### La statistica, che bella!

Alcuni tecnici esperti di informatica e statistica hanno fatto uno studio che con una frase e 4 numeri ci dice tanto, anzi moltissimo sulle potenzialità dell'AI e sulle prescrizione.

Chi ha scritto il titolo, nel caso migliore ha commesso un errore a mettere il virgolettato e avrebbe dovuto essere «il 40% degli esami è inutile» detto da chi ha fatto lo studio è equivalente ad una tolleranza del 3% massimo.

Secondo una regola di generale (1/√N), la tolleranza attesa su un campione di 17.000 elementi è del 2.3% da cui ho ricavato l'errore sulla percentuale ± 0.4% e ho inferito che quella dello studio fosse il 3% quindi solo il 42% è necessario, il 40% è inutile.

Possa Mr. Spock prendere a schiaffi chi ha scritto il titolo!

+

## Conclusione

L'AI in questo studio dimostra l'ipocrisia dell'umana natura per la quale il singolo medico tende a prescrivere almeno un 40% in più di esami diagnostici anche complessi per evitare responsabilità personali ma in questo modo creando un disservizio pari al 40% in pià di tempi di attesa o del 40% in più di costi, in uno scenario di risorse abbondanti, mentre in uno scenario di risorse scarse questi due fattori si moltiplicano fra loro (1.40 x 1.140 = 1.96) e l'efficienza complessiva del sistema si dimezza.

Senza contare che per il principio di pareto, è ragionevole pensare che l'80% di tutte le diagnosi inutili facciano capo ad un 20% di medici. Se questo fosse riconosciuto come un fatto emergente allora l'introduzione dell'AI anche come agente di analisi delle decisioni a posteriori potrebbe portare ad un profondo dilemma sia etico che giuridico: se relativamente pochi medici sono responsabili di dimezzare l'efficienza della sanità, qual'è la loro responsabilità personale?

L'AI come agente onesto pone l'uomo di fronte a se stesso alla realtà, come Giordano Bruno e Galileo Galilei in una società in cui gli outsider (2% della popolazione, Land, 1992) sono generalmente considerati un problema anche se attualmente non vengono trattati come un tempo si era solito fare con le streghe e gli eretici. Perché l'odore e il fumo di carne bruciata in un pubblico rogo non si addice più molto alle normative per la riduzione del particolato fine nei centri urbani!

- Continua in una [conversazione](https://g.co/gemini/share/71165e460d69) con Gemini e la relativa [tracrizione](not-yet.txt#?target=_blank)

+

## Share alike

&copy; 2025, **Roberto A. Foglietta** &lt;roberto.foglietta<span>@</span>gmail.com&gt;, [CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/)

</div>
