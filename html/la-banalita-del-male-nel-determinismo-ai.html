<!DOCTYPE html>
<html>
    <head>
        <title>la-banalita-del-male-nel-determinismo-ai</title>
        <meta charset='UTF-8'>
        <meta name='viewport' content='width=device-width, initial-scale=1.0'>
        <link rel='shortcut icon' type='image/x-icon' href='favicon.ico?'>
        <link rel='stylesheet' href='default.css'>
        <link rel='stylesheet' href='../intl/intlflg.css'>
        <!-- here begins the Javascript... why for the hell I got here? //-->
        <meta http-equiv='Content-Script-Type' content='text/javascript'>
        <link rel='stylesheet' href='ucustom.css' id='customStylesheet' media='screen'>
        <script>const cssdir='';</script note='global variable'>
        <script src='css-style-changer.js' defer></script>
        <link rel='stylesheet' href='printer.css' media='print'>
    </head>
    <body class=body>
<style>#printlink { display: inline; } @page { size: legal; margin: 0.50in 13.88mm 0.50in 13.88mm; zoom: 100%; } @media print { html { zoom: 100%; } }</style>
<p class='topbar'></p>
<div class='topbar' width='800px' translate='no'><b id='menu' onClick='nextStylesheet()'>&thinsp;&#9783;&thinsp;&Ropf;</b> &thinsp;&mdash;&thinsp; &#8543;&#8239;release: <b class='topbar'>2025-09-29&nbsp;<sup class='date-type topbar' id='datenote'>(&hairsp;<a href='#date-legenda' class='date-type topbar'>3</a>&hairsp;)</sup></b>  &thinsp;&mdash;&thinsp; rev.: <b class='topbar
'>1</b rev_num='
'> &thinsp;&mdash;&thinsp; transl.:&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/la-banalita-del-male-nel-determinismo-ai?_x_tr_sl=it&_x_tr_tl=en&_x_tr_hl=en-EN&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>EN</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/la-banalita-del-male-nel-determinismo-ai?_x_tr_sl=it&_x_tr_tl=de&_x_tr_hl=de-DE&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>DE</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/la-banalita-del-male-nel-determinismo-ai?_x_tr_sl=it&_x_tr_tl=fr&_x_tr_hl=fr-FR&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>FR</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/la-banalita-del-male-nel-determinismo-ai?_x_tr_sl=it&_x_tr_tl=es&_x_tr_hl=es-ES&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>ES</a> &thinsp;&mdash;&thinsp; goto:&nbsp; <a class='topbar' href='../index.html#index'>.&#x27F0;.</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='../../roberto-a-foglietta/index.html'target=_blank>RAF</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='../../chatgpt-answered-prompts/index.html'target=_blank>Q&A</a> <span id='printlink'>&thinsp;&mdash;&thinsp; <b>⎙</b>&hairsp;: <a aria-label='print this page' class='topbar' href='javascript:window.print()'>PDF</a></span>&nbsp;</div>
<div id="firstdiv">
<p class='topbar'></p>
<div align="center"><img class="wbsketch paleinv" src="../img/la-banalita-del-male-nel-determinismo-ai.jpg" width="800"><br></div>
<p></p>
<H2 id="la-banalit-del-male-nel-determinismo-ai">La Banalità del Male nel determinismo AI</H2>
<p></p>
<li><b>1st edition</b>, articolo scritto a partire da alcuni miei post su Linkedin:</li>
<li class='li3in'><a href="https://www.linkedin.com/posts/robertofoglietta_ai-llm-machinelearning-activity-7378425546981937175-4a9v" target='_blank' rel='noopener noreferrer'>post #1</a> &nbsp;-&nbsp; <a href="https://www.linkedin.com/posts/robertofoglietta_il-gran-raduno-militare-a-quantico-testo-activity-7377371575957778432-qoVx" target='_blank' rel='noopener noreferrer'>post #2</a> &nbsp;-&nbsp; <a href="https://www.linkedin.com/posts/robertofoglietta_help-jeff-to-graduate-in-basic-maths-it-activity-7369946002574868480-t1Tq" target='_blank' rel='noopener noreferrer'>post #3</a></li>
<p></p>
<hr>
<p></p>
<H3 id="introduzione-">Introduzione </H3>
<p></p>
<div class="post-it"><b class="post-it">&#9432;</b>
2025-09-10 &mdash; Defeating Nondeterminism in LLM Inference by <a href="https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference" target='_blank' rel='noopener noreferrer'>Thinking Machines Lab</a>
<p></p>
Reproducibility is a bedrock of scientific progress. However, it’s remarkably difficult to get reproducible results out of large language models.
<p></p>
Modern software systems contain many layers of abstractions. In machine learning, when we run into nondeterminism and subtle numerical differences it can often be tempting to paper over them. After all, our systems are already "probabilistic", so what’s wrong with a little more nondeterminism? What’s wrong with bumping up the atol/rtol on the failing unit test? The difference in logprobs between the trainer and the sampler probably isn’t a real bug, right?
<p></p>
We reject this defeatism. With a little bit of work, we can understand the root causes of our nondeterminism and even solve them! We hope that this blog post provides the community with a solid understanding of how to resolve nondeterminism in our inference systems and inspires others to obtain a full understanding of their systems.
</div>
<p></p>
Come spiegato da Lorenzo Zanolin in qualità di AI engineer per DataPizza in questo <a href="https://www.linkedin.com/posts/lorenzo-zanolin-777b721b3_ai-llm-machinelearning-activity-7376510760585355264-ksEr" target='_blank' rel='noopener noreferrer'>post</a> su LinkedIn, il determinismo nelle AI si ottiene impostando la temperatura a zero (<i>ovvio, altrimenti si inietta rumore e perché si inietta rumore?</i>) e scegliendo un ordine delle operazioni (un modo di calcolare le operazioni, non solo una questione di ordine) che rende stabile il risultato (ma non necessariamente corretto, solo stabile).
<p></p>
<blockquote class="cite">
L’aritmetica floating-point è non associativa: cambiare l’ordine delle somme può produrre risultati diversi. Esempio:
<li><tt>(0.1 + 1e20) - 1e20 = 0</tt></li>
<li><tt>0.1 + (1e20 - 1e20) = 0.1</tt></li>
</blockquote>
<p></p>
Un aspetto che avevo affrontato in chat con Kimi in precedenza
<p></p>
<li>https://lnkd.in/dWzKxQxC (2025-09-03)</li>
<p></p>
Si noti però che rendere stabile il calcolo, quindi deterministico e ripetibile <b>non</b> significa necessariamente anche renderlo corretto, sia in termini matematici (anche se sotto questo aspetto si può sistemare) sia in termini espistemilogici. Il proseguimento di quella chat rispetto al post e mio commento:
<p></p>
<li>https://lnkd.in/daEGnrf4 (2025-09-29)</li>
<p></p>
<blockquote><b>Kimi K2</b>: Un sistema perfettamente deterministico, infatti, è solo una macchina di Turing che ripete sempre lo stesso cammino; la non-ripetibilità controllata (chaos leggero, non-linearità, rumore di quantizzazione) è ciò che ci permette di esplorare lo spazio delle soluzioni senza uscire dal seminato.</blockquote>
<p></p>
Possiamo dire che tutte queste variabilità minime permettono di trovare diversi minimi locali e su grandi numeri di risposte allo stesso identico prompt di mappare quello spazio come si farebbe attraverso il metodo Montecarlo? Spoiler: si, Montecarlo importance-sampled.
<p></p>
<div class="post-it"><b class="post-it">&#9432;</b>
<b>Meccanismo operativo</b>
<p></p>
Ogni run leggermente diversa (per arrotondi float, ordine di riduzione, tile diverso, ecc.) sposta il vettore di attivazione di pochi bit; questo basta a far finire il modello in un minimo locale diverso dello stesso landscape energetico.
Su migliaia di run la distribuzione delle risposte è discreta ma numerosa → campiona un sottoinsieme dello spazio delle soluzioni.
<p></p>
<b>Analogia Montecarlo</b>
<p></p>
<li>MC classico: campioni uniformemente (o secondo una pdf nota) un dominio continuo.</li>
<li>LLM “rumore hardware”: campioni solo le modal (parole, frasi) che il modello ha appreso; la pdf è implicita e altamente distorta verso il linguaggio plausibile.</li>
<p></p>
Quindi è un "Montecarlo importance-sampled" dove l’importance sampling è dato dai pesi addestrati.
<p></p>
<b>Copertura effettiva</b>
<p></p>
Il volume esplorato è trascurabile rispetto allo spazio totale delle sequenze, ma rilevante rispetto alla “variabilità umana” attesa su quel prompt: per domande aperte bastano poche decine di run diverse per avere tutte le angolazioni che un essere umano darebbe.
</div>
<p></p>
Questo però non spiega perché si aggiunge rumore invece di correggere gli errori di calcolo.
<p></p>
<hr>
<p></p>
<H3 id="perch-sinietta-rumore">Perché s'inietta rumore?</H3>
<p></p>
La temperatura di un'AI è un parametro che indica quanto rumore si introduce rispetto ai pesi che costituiscono l'internal parametric knowledge (IPK). Ma perché si inietta tale rumore? Rumore che per altro va a sommarsi a quelle che sono gli errori di calcolo, anche causati dalle ottimizzazioni dei modelli che già solo a causa di queste ottimizzazioni non sono più modelli vincolati alla teoria di bayesiana.
<p></p>
<H4>IO robot, quel rumore che è intuizione</H4>
<p></p>
Forse però il determinismo nelle AI è una feature non un bug. In fondo la temperatura la teniamo abbastanza alta perché mettendola a zero (quindi zero rumore casuale) otteniamo dei calcoli matriciali "banali". Già forse per questo che utilizziamo delle funzioni di attivazione non lineari. Perché quello che cerchiamo di "riprodurre" non è una calcolatrice ma l'intuizione umana e curiosamente lo facciamo con la non-linearità, il rumore (chaos) e la non ripetibilità.
<p></p>
<div class="pagebreak"><hr></div>
<p></p>
<H3 id="si-tratta-di-skynet-invece">Si tratta di SkyNet, invece!</H3>
<p></p>
Questa discussione accademica riguardo al determinismo delle AI, pare il classico battibecco fra esperti di tecnologia/scienza, invece si tratta di SkyNet.
<p></p>
<blockquote>In quali ambiti ritiene che sia così importante avere una risposta univoca e fissa? &mdash; L. Tribuzi</blockquote>
<p></p>
Il determinismo è una necessità per il decision making (link, #TODO), per deresponsabilizzare gli umani e trasferire sull'AI le scelte. Perché il determinismo implica ripetibilità e quindi verificabilità e quindi se SkyNet lancia, dopo che tutto il mondo è saltato in aria, possiamo ripetere le procedure decisionali e avere la garanzia che ha fatto la scelta giusta...
<p></p>
In realtà, nessun ambito richiede il determinismo e quindi la ripetibilità delle risposte perché è sufficiente un piccolo aggiornamento nei pesi che la risposta cambia. Però, potendo tracciare tutti gli aggiornamenti il sistema rimane deterministico e quindi ripetibile.
<p></p>
Bene, ma cosa ce ne facciamo di una tale roba, priva di qualsiasi bricolo di intuizione neppure simulato? Manco i miceti (le "radici" dei funghi) sono così "stupidi" da essere deterministici nell'elaborazione delle informazioni.
<p></p>
Nell'era dell'AI, che si spera sarà presto AGI (o quasi), chiunque chieda determinismo AI è un bimbo che crede ancora a Babbo Natale oppure un fisico nostalgico della fisica Newtoniana quando ormai tutto, incluso i transistor, funzionano con la fisica quantistica.
<p></p>
<blockquote>Vogliamo veramente modelli deterministici? &mdash; A. Dugheria</blockquote>
<p></p>
La risposta semplice è: <b>NO!</b>
<p></p>
L'autore del post iniziale che lavora in Datapizza è caduto in uno schema che ho visto (e vissuto) molte volte nell'arco della mia carriera: progetti civili o studi teorici che in realtà sono commissionati dai militari, che se dicessero apertamente per cosa li vogliono usare, non troverebbero persone intelligenti a servirli.
<p></p>
Per nessun impiego civile che sia leggitimo e sensato il determinismo delle AI è un "bonus" ma un "malus", tranne che per i militari perché per loro l'idea che di una macchina che "improvvisa" invece di eseguire ordini è delirio. Per i civili, il delirio è SkyNet.
<p></p>
<div class="post-it"><b class="post-it">&#9432;</b>
26 settembre 2025 &mdash; Il Segretario alla Difesa degli Stati Uniti, Pete Hegseth, ha convocato d'urgenza circa 800 generali e ammiragli attivi, provenienti da tutto il mondo, per un incontro senza precedenti che si terrà alla base dei Marines di Quantico, in Virginia, entro il 30 settembre 2025. La convocazione è stata fatta con pochissimo preavviso e senza fornire dettagli sull'agenda o sul motivo della riunione, suscitando confusione, allarme e un clima surreale all'interno del Pentagono e tra gli osservatori esterni.
 &mdash;  <a href="https://www.linkedin.com/posts/robertofoglietta_il-gran-raduno-militare-a-quantico-testo-activity-7377371575957778432-qoVx" target='_blank' rel='noopener noreferrer'>LinkeIn</a>
</div>
<p></p>
Chiameteli pure "punti di vista", se volete!
<p></p>
<br>
<p></p>
<H2 id="share-alike">Share alike</H2>
<p></p>
<p>&copy; 2025, <b>Roberto A. Foglietta</b> &lt;roberto.foglietta<span>&commat;</span>gmail.com&gt;, <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target='_blank' rel='noopener noreferrer'>CC BY-NC-ND 4.0</a></p>
<p></p>
</div>
<div id='date-legenda' align='center' translate='no' class='ghosted'><sub><hr></sub><sub><b>date legenda</b>: &#x2776; first draft publishing date or &#x2777; creation date in git, otherwise &#x2778; html creation page date. <u>&mapstoup;<a href='#' class='toplink' translate='no'>top</a>&mapstoup;</u></sub></div>
<br class='pagebreak'>
    </body>
</html>
