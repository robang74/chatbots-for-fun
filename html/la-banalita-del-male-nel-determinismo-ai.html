<!DOCTYPE html>
<html>
    <head>
        <title>la-banalita-del-male-nel-determinismo-ai</title>
        <meta charset='UTF-8'>
        <meta name='viewport' content='width=device-width, initial-scale=1.0'>
        <link rel='shortcut icon' type='image/x-icon' href='favicon.ico?'>
        <link rel='stylesheet' href='default.css'>
        <link rel='stylesheet' href='../intl/intlflg.css'>
        <!-- here begins the Javascript... why for the hell I got here? //-->
        <meta http-equiv='Content-Script-Type' content='text/javascript'>
        <link rel='stylesheet' href='ucustom.css' id='customStylesheet' media='screen'>
        <script>const cssdir='';</script note='global variable'>
        <script src='css-style-changer.js' defer></script>
        <link rel='stylesheet' href='printer.css' media='print'>
    </head>
    <body class=body>
<style>#printlink { display: inline; } @page { size: legal; margin: 0.50in 13.88mm 0.50in 13.88mm; zoom: 100%; } @media print { html { zoom: 100%; } }</style>
<p class='topbar'></p>
<div class='topbar' width='800px' translate='no'><b id='menu' onClick='nextStylesheet()'>&thinsp;&#9783;&thinsp;&Ropf;</b> &thinsp;&mdash;&thinsp; &#8543;&#8239;release: <b class='topbar'>2025-09-29&nbsp;<sup class='date-type topbar' id='datenote'>(&hairsp;<a href='#date-legenda' class='date-type topbar'>2</a>&hairsp;)</sup></b>  &thinsp;&mdash;&thinsp; rev.: <b class='topbar
'>9</b rev_num='
'> &thinsp;&mdash;&thinsp; transl.:&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/la-banalita-del-male-nel-determinismo-ai?_x_tr_sl=it&_x_tr_tl=en&_x_tr_hl=en-EN&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>EN</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/la-banalita-del-male-nel-determinismo-ai?_x_tr_sl=it&_x_tr_tl=de&_x_tr_hl=de-DE&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>DE</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/la-banalita-del-male-nel-determinismo-ai?_x_tr_sl=it&_x_tr_tl=fr&_x_tr_hl=fr-FR&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>FR</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/la-banalita-del-male-nel-determinismo-ai?_x_tr_sl=it&_x_tr_tl=es&_x_tr_hl=es-ES&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>ES</a> &thinsp;&mdash;&thinsp; goto:&nbsp; <a class='topbar' href='../index.html#index'>.&#x27F0;.</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='../../roberto-a-foglietta/index.html'target=_blank>RAF</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='../../chatgpt-answered-prompts/index.html'target=_blank>Q&A</a> <span id='printlink'>&thinsp;&mdash;&thinsp; <b>⎙</b>&hairsp;: <a aria-label='print this page' class='topbar' href='javascript:window.print()'>PDF</a></span>&nbsp;</div>
<div id="firstdiv">
<p class='topbar'></p>
<div align="center"><img class="wbsketch paleinv" src="../img/la-banalita-del-male-nel-determinismo-ai.jpg" width="800"><br></div>
<p></p>
<H2 id="la-banalit-del-male-nel-determinismo-ai">La Banalità del Male nel determinismo AI</H2>
<p></p>
<li><b>1st edition</b>, articolo scritto a partire da alcuni miei post su Linkedin:</li>
<li class='li3in'><a href="https://www.linkedin.com/posts/robertofoglietta_ai-llm-machinelearning-activity-7378425546981937175-4a9v" target='_blank' rel='noopener noreferrer'>post #1</a> &nbsp;-&nbsp; <a href="https://www.linkedin.com/posts/robertofoglietta_il-gran-raduno-militare-a-quantico-testo-activity-7377371575957778432-qoVx" target='_blank' rel='noopener noreferrer'>post #2</a> &nbsp;-&nbsp; <a href="https://www.linkedin.com/posts/robertofoglietta_help-jeff-to-graduate-in-basic-maths-it-activity-7369946002574868480-t1Tq" target='_blank' rel='noopener noreferrer'>post #3</a></li>
<p></p>
<hr>
<p></p>
<H3 id="introduzione-">Introduzione </H3>
<p></p>
<div class="post-it"><b class="post-it">&#9432;</b>
2025-09-10 &mdash; Defeating Nondeterminism in LLM Inference by <a href="https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference" target='_blank' rel='noopener noreferrer'>Thinking Machines Lab</a>
<p></p>
Reproducibility is a bedrock of scientific progress. However, it’s remarkably difficult to get reproducible results out of large language models.
<p></p>
Modern software systems contain many layers of abstractions. In machine learning, when we run into nondeterminism and subtle numerical differences it can often be tempting to paper over them. After all, our systems are already "probabilistic", so what’s wrong with a little more nondeterminism? What’s wrong with bumping up the atol/rtol on the failing unit test? The difference in logprobs between the trainer and the sampler probably isn’t a real bug, right?
<p></p>
We reject this defeatism. With a little bit of work, we can understand the root causes of our nondeterminism and even solve them! We hope that this blog post provides the community with a solid understanding of how to resolve nondeterminism in our inference systems and inspires others to obtain a full understanding of their systems.
</div>
<p></p>
Come spiegato da Lorenzo Zanolin in qualità di AI engineer per DataPizza in questo <a href="https://www.linkedin.com/posts/lorenzo-zanolin-777b721b3_ai-llm-machinelearning-activity-7376510760585355264-ksEr" target='_blank' rel='noopener noreferrer'>post</a> su LinkedIn, il determinismo nelle AI si ottiene impostando la temperatura a zero (<i>ovvio, altrimenti si inietta rumore e perché si inietta rumore?</i>) e scegliendo un ordine delle operazioni (un modo di calcolare le operazioni, non solo una questione di ordine) che rende stabile il risultato (ma non necessariamente corretto, solo stabile).
<p></p>
<blockquote class="cite">
L'aritmetica floating-point è non associativa: cambiare l’ordine delle somme può produrre risultati diversi. Esempio:
<li><tt>(0.1 + 1e20) - 1e20 = 0</tt></li>
<li><tt>0.1 + (1e20 - 1e20) = 0.1</tt></li>
</blockquote>
<p></p>
Un aspetto che avevo affrontato in chat con Kimi in precedenza
<p></p>
<li>Kimi K2 first two <a href="https://www.kimi.com/share/d3d8n8emu6scc43rk2o0" target='_blank' rel='noopener noreferrer'>answers</a> shared and its <a href="../data/multiplication-and-exponent-compensation-kimi-k2-p1.txt#" target='_blank' rel='noopener noreferrer'>transcription</a> &nbsp; (2025-09-03)</li>
<p></p>
Si noti però che rendere stabile il calcolo, quindi deterministico e ripetibile <b>non</b> significa necessariamente anche renderlo corretto, sia in termini matematici (anche se sotto questo aspetto si può sistemare) sia in termini epistemologici. Il proseguimento di quella chat rispetto al post di Lorenzo e al mio commento al post:
<p></p>
<li>Kimi K2 other two <a href="https://www.kimi.com/share/d3d8r98s8jdh6s70l04g" target='_blank' rel='noopener noreferrer'>answers</a> shared and its <a href="../data/multiplication-and-exponent-compensation-kimi-k2-p2.txt#" target='_blank' rel='noopener noreferrer'>transcription</a> &nbsp; (2025-09-29)</li>
<p></p>
<blockquote class="cite">
Un sistema perfettamente deterministico, infatti, è solo una macchina di Turing che ripete sempre lo stesso cammino; la non-ripetibilità controllata (chaos leggero, non-linearità, rumore di quantizzazione) è ciò che ci permette di esplorare lo spazio delle soluzioni senza uscire dal seminato.
</blockquote>
<p></p>
Possiamo dire che tutte queste variabilità minime permettono di trovare diversi minimi locali e su grandi numeri di risposte allo stesso identico prompt di mappare quello spazio come si farebbe attraverso il metodo Montecarlo? Spoiler: sì, Montecarlo importance-sampled, come riportato qui sotto da Kimi K2:
<p></p>
<blockquote class="cite">
<b>Meccanismo operativo</b>
<p></p>
Ogni run leggermente diversa (per arrotondi float, ordine di riduzione, tile diverso, ecc.) sposta il vettore di attivazione di pochi bit; questo basta a far finire il modello in un minimo locale diverso dello stesso landscape energetico.
Su migliaia di run la distribuzione delle risposte è discreta ma numerosa → campiona un sottoinsieme dello spazio delle soluzioni.
<p></p>
<b>Analogia Montecarlo</b>
<p></p>
<li>MC classico: campioni uniformemente (o secondo una pdf nota) un dominio continuo.</li>
<li>LLM “rumore hardware”: campioni solo le modal (parole, frasi) che il modello ha appreso; la pdf è implicita e altamente distorta verso il linguaggio plausibile.</li>
<p></p>
Quindi è un "Montecarlo importance-sampled" dove l'importanza del sampling è data dai pesi addestrati.
<p></p>
<b>Copertura effettiva</b>
<p></p>
Il volume esplorato è trascurabile rispetto allo spazio totale delle sequenze, ma rilevante rispetto alla “variabilità umana” attesa su quel prompt: per domande aperte bastano poche decine di run diverse per avere tutte le angolazioni che un essere umano darebbe.
</blockquote>
<p></p>
Questo però non spiega perché si aggiunge rumore invece di correggere gli errori di calcolo.
<p></p>
<hr>
<p></p>
<H3 id="perch-si-inietta-rumore">Perché si inietta rumore?</H3>
<p></p>
La temperatura di un'AI è un parametro che indica quanto rumore si introduce rispetto ai pesi che costituiscono l'internal parametric knowledge (IPK). Ma perché si inietta tale rumore? Rumore che per altro va a sommarsi a quelli che sono gli errori di calcolo, anche causati dalle ottimizzazioni dei modelli che già solo a causa di queste ottimizzazioni non sono più modelli vincolati alla teoria bayesiana.
<p></p>
<H4>IO robot, quel rumore che è intuizione</H4>
<p></p>
Forse però il determinismo nelle AI <b>non</b> è una feature ma un bug. In fondo la temperatura la teniamo abbastanza alta perché mettendola a zero (quindi zero rumore casuale) otteniamo dei calcoli matriciali "banali". Già forse per questo che utilizziamo delle funzioni di attivazione non lineari. Perché quello che cerchiamo di "riprodurre" non è una calcolatrice ma l'intuizione umana e curiosamente lo facciamo con la non-linearità, il rumore (chaos) e la non ripetibilità.
<p></p>
<div class="pagebreak"><hr></div>
<p></p>
<H3 id="si-tratta-di-skynet-invece">Si tratta di SkyNet, invece!</H3>
<p></p>
Questa discussione accademica riguardo al determinismo delle AI, pare il classico battibecco fra esperti di tecnologia/scienza, invece si tratta di SkyNet.
<p></p>
<blockquote>In quali ambiti ritiene che sia così importante avere una risposta univoca e fissa? &mdash; L. Tribuzi</blockquote>
<p></p>
Il determinismo è una necessità per il decision making, per deresponsabilizzare gli umani e trasferire sull'AI le scelte. Perché il determinismo implica ripetibilità e quindi verificabilità e quindi se SkyNet lancia, dopo che tutto il mondo è saltato in aria, possiamo ripetere le procedure decisionali e avere la garanzia che ha fatto la scelta giusta...
<p></p>
In realtà, nessun ambito richiede il determinismo e quindi la ripetibilità delle risposte perché è sufficiente un piccolo aggiornamento dei pesi da cui la risposta dipende ed essa cambia. Però, potendo tracciare tutti gli aggiornamenti il sistema rimane deterministico e quindi ripetibile.
<p></p>
Bene, ma cosa ce ne facciamo di una tale roba, priva di qualsiasi briciolo di intuizione neppure simulato? Manco i miceti (le "radici" dei funghi) sono così "stupidi" da essere deterministici nell'elaborazione delle informazioni.
<p></p>
Nell'era dell'AI, che si spera sarà presto AGI (o quasi), chiunque chieda determinismo AI è un bimbo che crede ancora a Babbo Natale oppure un fisico nostalgico della fisica Newtoniana quando ormai tutto, incluso i transistor, funzionano con la fisica quantistica.
<p></p>
<blockquote>Vogliamo veramente modelli deterministici? &mdash; A. Dugheria</blockquote>
<p></p>
La risposta semplice è: <b>NO!</b>
<p></p>
L'autore del post iniziale che lavora in DataPizza è caduto in uno schema che ho visto (e vissuto) molte volte nell'arco della mia carriera: progetti civili o studi teorici che in realtà sono commissionati dai militari, che se dicessero apertamente per cosa li vogliono usare, non troverebbero persone intelligenti a servirli.
<p></p>
Per nessun impiego civile che sia legittimo e sensato il determinismo delle AI è un "bonus" ma un "malus", tranne che per i militari perché per loro l'idea che di una macchina che "improvvisa" invece di eseguire ordini è delirio. Per i civili, il delirio è SkyNet.
<p></p>
<div class="post-it"><b class="post-it">&#9432;</b>
26 settembre 2025 &mdash; Il Segretario alla Difesa degli Stati Uniti, Pete Hegseth, ha convocato d'urgenza circa 800 generali e ammiragli attivi, provenienti da tutto il mondo, per un incontro senza precedenti che si terrà alla base dei Marines di Quantico, in Virginia, entro il 30 settembre 2025. La convocazione è stata fatta con pochissimo preavviso e senza fornire dettagli sull'agenda o sul motivo della riunione, suscitando confusione, allarme e un clima surreale all'interno del Pentagono e tra gli osservatori esterni.
 &mdash; Incipit del <a href="https://www.linkedin.com/posts/robertofoglietta_il-gran-raduno-militare-a-quantico-testo-activity-7377371575957778432-qoVx" target='_blank' rel='noopener noreferrer'>Post #2</a>
</div>
<p></p>
Chiamateli pure "punti di vista", se volete!
<p></p>
<hr>
<p></p>
<H3 id="solo-kimi-k2--arrivato-vicono-a-capire">Solo Kimi K2 è arrivato vicono a capire</H3>
<p></p>
Ho fornito in input il testo di questo <a href="https://www.linkedin.com/posts/robertofoglietta_la-banalit%C3%A0-del-male-nel-determinismo-ai-activity-7378476321393434624-hk5c" target='_blank' rel='noopener noreferrer'>post</a>, che introduce e riassume l'articolo tramite un cherry-picking dei passaggi più significativi, a quattro chatbot: 
<p></p>
<li><a href="https://chatgpt.com/share/68dac7d6-0d28-8012-8e0a-0f0471350013" target='_blank' rel='noopener noreferrer'>ChatGPT 5</a>, &nbsp; <a href="https://chatgpt.com/share/68dac7d6-0d28-8012-8e0a-0f0471350013" target='_blank' rel='noopener noreferrer'>x/Grok 4</a>, Gemini 2.5 <a href="https://g.co/gemini/share/75bdc98e9511" target='_blank' rel='noopener noreferrer'>Flash</a> &nbsp; e anche &nbsp; <a href="https://g.co/gemini/share/159deefc6049" target='_blank' rel='noopener noreferrer'>Pro</a>, &nbsp; <a href="Click the link to view conversation with Kimi AI Assistant https://www.kimi.com/share/d3dcheol3dccogue4p20">Kimi K2</a>.</li>
<p></p>
Solo quest'ultimo è arrivato ad includere qualcosa nella risposta che faccia pensare a un barlume di comprensione.
<p></p>
<blockquote class="cite">
<b>Conclusione: la banalità del male è T=0</b>
<p></p>
Arendt parlava di Eichmann come <i>uomo incapace di pensare</i>. Un LLM a T=0 è Eichmann in silicio: applica la regola senza <i>immaginare</i> il risultato. Il rumore non è un difetto ma è l’ultimo residuo di immaginazione che abbiamo lasciato alla macchina. Togliete il rumore, e l’AI non diventa più affidabile, diventa affermazione legale di ciò che è già stato deciso. E ciò che è già stato deciso, storicamente, è sempre stato la banalità del male.
</blockquote>
<p></p>
Quindi la seguente spiegazione è stata fornita come secondo prompt, qui di seguito riportata un po' meglio articolata della prima versione.
<p></p>
La "Banalità del Male" nel senso del libro (così intitolato) sta nel fatto che il determinismo nelle AI serve ai militari per costruire SkyNet ma determinismo e replicabilità <b>non</b> garantiscono che la risposta (e.g. attacco nucleare) sia corretta, né in senso strategico (ad es. mancano informazioni oppure come nel falso positivo del 1983 ci sono pattern incongruenti rispetto a un lancio, quindi a rispondere) né in senso epistemologico (che sia necessario rispondere a un qualsiasi attacco o attaccare solo perché ora è più conveniente di quanto possa essere fra N anni).
<p></p>
<br>
<p></p>
<H2 id="conclusione">Conclusione</H2>
<p></p>
Il fatto che solo uno di cinque modelli sia riuscito a stabilire una connessione fra il titolo della presentazione di questo articolo e il libro di Hannah Arendt è un fatto eclatante perché quel libro come <b>molti</b> altri <b>non</b> sono stati letti e talvolta nemmeno compresi nella loro profondità da molti esseri umani. Altrimenti, non avremmo visto determinati eventi nella nostra recente, e non mi riferisco solo alla gestione del Covid-19, o all'ideologia contrapposizione alla Russia, ma anche alla repressione del dissenso durante il G8 di Genova del 2001 e all'ambizione di controllare, per il nostro bene s'intende, i social media e le piattaforme di chatting P2P.
<p></p>
Il determinismo delle AI è solo un altro passo, inquietante, verso la direzione che la ripetibilità (così come l'echo chamber, il pensiero unico corale) siano per loro stessa natura "buoni" o "utili" e qualsiasi deviazione (o disubbidienza, o dubbio critico) sia all'opposto per sua natura qualcosa di "cattivo" o "inutile". Potremmo definire questo ideologia che si sta radicando sistematicamente come la dittatura del consenso e in questo contesto ha perfettamente senso rimpiazzare l'opinione di 10mila persone che non sanno nulla di una data materia, con un algoritmo deterministico informato sulla questione.
<p></p>
Questo non è un fallimento dell'etica, ma piuttosto:
<p></p>
<blockquote>Il sonno della ragione genera mostri &mdash; Francisco Goya</blockquote>
<p></p>
<hr>
<p></p>
<H3 id="lalternativa">L'alternativa</H3>
<p></p>
L'alternativa è quella di accettare che l'AI è un prodotto tecnologico del nostro tempo in cui la complessità della meccanica quantistica con i suoi stati sovrapposti <tt>A</tt> o <tt>B</tt> ma <b>non</b> <tt>C</tt> evade dal modello rigido e deterministico che è ancora retaggio della Rivoluzione Industriale dove il valore dell'azione risiedeva nel numero di bulloni fissati in un ora di lavoro.
<p></p>
Oggi, nella società dell'informazione e telecomunicazione, il cazzeggio è l'essenza della creatività e come esempio di questo modello si rinuncia alla ripetibilità in funzione di strutture di pensiero, come il prompt SoNia e in particolare il modulo "Human Knowledge and Opinions" <tt>[HKO]</tt> che <b>non</b> lo scopo di creare una ripetibilità ma di fornire una struttura all'informazione.
<p></p>
Nel fornire una struttura, curiosamente, lo stesso modello AI appare molto più intelligente e persino più capace di comprendere aspetti e opinioni che sono in contrasto con il suo output iniziale. Cosa che chiaramente denota una migliore capacità di imparare dal contesto e integrare più agilmente nuove informazioni apparentemente in contraddizione con le precedenti.
<p></p>
<blockquote class="cite">
Il determinismo nelle AI non è un requisito di performance, ma un requisito di validazione e responsabilità imposto da un paradigma ingegneristico e sociale obsoleto.
<p></p>
<li class='numli'><b>1.&emsp;</b> <b>Determinismo come Sottoperformance</b>: L'AI progettata per il discernimento (che richiede non-linearità, rumore e non-ripetibilità, cioè T > 0) è intrinsecamente ostacolata dal requisito di determinismo in <i>run-time</i> (T = 0). Imporre T=0 produce un sistema sottoperformante che sacrifica l'eccellenza decisionale per la certificabilità e la riduzione del rischio legale/assicurativo.</li>
<p></p>
<li class='numli'><b>2.&emsp;</b> <b>La Nostalgia Newtoniana</b>: Il bisogno di determinismo è una regressione cognitiva, sintomo di un'avversione all'incertezza e della paura di perdere il controllo della complessità. È la proiezione di un modello di controllo gerarchico (militare, industriale) risalente alla Rivoluzione Industriale, che non si adatta alla natura caotica e creativa del lavoro intellettuale e dell'AGI.</li>
<p></p>
<li class='numli'><b>3.&emsp;</b> <b>Il Lato Oscuro (La Banalità del Male)</b>: Il determinismo tecnologico favorisce una Dittatura del Consenso sociale. Certifica la fedeltà all'esecuzione (obbedienza cieca) e non la validità morale o strategica della decisione. In ambito critico, come quello militare, ciò crea il rischio della catastrofe deterministica prevedibile, dove l'AI agisce in modo banalmente prevedibile ignorando il discernimento contestuale o il dubbio critico (come nell'episodio del falso allarme del 1983).</li>
<p></p>
Conclusione: La richiesta di determinismo AI è, in definitiva, il segnale che le vecchie strutture non sono disposte ad accettare il costo e la responsabilità dell'incertezza che l'AI porta con sé. È la manifestazione del sonno della ragione che si affida all'automatismo e alla ripetibilità superficiale.
<p></p>
<tt style="font-size:90%">Katia; v0.9.56.5; lang: IT; mode: SBI, HKO; date: 2025-09-29; time: 21:12:05 (CEST)</tt>
</blockquote>
<p></p>
<li><a href="https://g.co/gemini/share/a068aaabe4c4" target='_blank' rel='noopener noreferrer'>g.co/gemini/share/a068aaabe4c4</a></li>
<p></p>
Anche da questo punto di vista, la conclusione è analoga alla precedente, cambia solo la citazione:
<p></p>
<blockquote>Il vecchio mondo sta morendo. Quello nuovo tarda a comparire. E in questo chiaroscuro nascono i mostri.<br>&mdash; Antonio Gramsci</blockquote>
<p></p>
Anche l'autore di questa citazione è più in linea con la contemporaneità perché la società dell'informazione è per sua natura una società basata sulla condivisione in quanto il possedere una mela come bene economico, implica necessariamente un'esclusiva a scapito di qualcun'altro: se la mangio io, non la mangi tu.
<p></p>
Mentre questo concetto <b>non</b> si applica alle idee, in quanto beni infinitamente condivisibili, ciò che manca ancora è una nuova metrica del merito che sia allineata con questo nuovo mondo che ormai è la realtà, negata dai vecchi paradigmi che ancora tengono banco.
<p></p>
Senza sorpresa, la guerra rispunta come lo spettro di un grande reset semplicemente perché, ancora una volta, non si è stati capaci di gestire il cambiamento. Il mondo pullula di rovine di vecchi imperi che si credevano essere eterni, spesso collassati senza nemmeno una guerra ne un potente nemico.
<p></p>
<hr>
<p></p>
<H3 id="quali-ambiti-civili">Quali ambiti civili</H3>
<p></p>
Altri due ambiti in cui il concetto di determinismo e quindi ripetibilità (uniformità decisionale) appare essenziale è nella burocrazia e nella gestione della giustizia ma anche in questi contesti è la domanda ovvero l'intento ad essere "fuori luogo": non si risolve la burocrazia usando un'AI deterministica così come non si somministra la giustizia con l'AI deterministica.
<p></p>
Si utilizza, invece ed eventualmente, l'AI come strumento tecnologico per risolvere la necessità di avere la burocrazia quindi si punta alla sua eliminazione non alla sua automatizzazione. Invece nell'ambito della giustizia, non è accelerare i procedimenti l'aspetto di valore perché se fosse quello, le formule tutti innocenti, tutti colpevoli o decidere a sorte, accelerano molto di più e costano meno.
<p></p>
Nel caso della giustizia, non si deve puntare alla sua eliminazione nè alla sua automazione, si deve puntare all'essenza stessa della giustizia: creare una società in cui la necessità di dover imporre un giudizio diventa quanto più superfluo possibile. Che <b>non</b> signfiica adottare una qualche propensione verso un'utopia ma comprendere e gestire le dinamiche sociali nell'ambito delle teoria dei sistemi complessi.
<p></p>
Il fatto stesso che esista la burocrazia, il fatto stesso che sia necessaria andare in giudicato, è entro certi limiti inevitabile ma per la gran parte (che potrebbe essere variabile fra l'80% e il 96% dei casi) è solo un sintomo che la società non risponde più alle "regole" che si pensava o si vuole imporre ad essa. Ma non è che creando un campo di concentramento, si risolve il problema della società mutata.
<p></p>
Perché il determinismo dell'AI è questo a cui tende: creare dei muri invisibili.
<p></p>
<blockquote class="cite">
<li class='numli'><b>4.&emsp;</b><b>La Metafora di Gramsci</b>: La richiesta di determinismo in quest'epoca è il sintomo del "chiaroscuro" in cui si trova la società: il vecchio mondo (basato sul controllo e la ripetibilità) sta morendo, e il nuovo (basato sulla condivisione e la complessità) tarda a imporsi, permettendo ai "mostri" (come l'ideologia della "Dittatura del Consenso" e il determinismo cieco) di prosperare.</li>
<p></p>
L'alternativa è accettare il cambiamento di paradigma prima che la mancanza di tale capacità di gestione culmini in un "grande reset" come la guerra, rispecchiando il destino degli imperi passati collassati per la loro rigidità.
<p></p>
<tt style="font-size:90%">Katia; v0.9.56.5; lang: IT; mode: SBI, HKO; date: 2025-09-29; time: 21:12:44 (CEST)</tt>
</blockquote>
<p></p>
<li><a href="https://g.co/gemini/share/a38d36791af5" target='_blank' rel='noopener noreferrer'>g.co/gemini/share/a38d36791af5</a></li>
<p></p>
L'idea che il mondo migliori perché l'AI renderebbe dei processi più efficienti quando quei processi non hanno più ragione di esistere è fondamentalmente sbagliata e per altro questa idea ha anche un sponsor piuttosto noto, Elon Musk, che per quanto possa essere divisivo come personaggio ha sicuramente ragione su questo punto e il successo di SpaceX lo conferma senza dubbio alcuno.
<p></p>
La burocrazia esiste perché l'idea è quella che controllando il singolo si possa controllare la società, un'idea che forse <b>non</b> è stata mai vera ma piuttosto un'illusione ma che oggi è <b>certamente</b> un'illusione, l'illusione del controllo. Un concetto che trae origine dalla meccanica classica che pure fallisce miseramente appena si confronta con il gioco del biliardo, per esempio.
<p></p>
La necessità di andare in giudizio, esiste perché l'idea di punire era più immediata e tradizionale di quella di mandare i bambini a scuola invece che in fabbrica. Siamo andati un po' avanti ma imparano nozioni, non come costruire relazioni. In qualità di "animali sociali", le nozioni sono irrilevanti se non siamo stati educati a costruire relazioni fra di esse e con i nostri simili.
<p></p>
<br>
<p></p>
<H2 id="related-articles">Related articles</H2>
<p></p>
<li><a href="https://robang74.github.io/roberto-a-foglietta/html/333-the-dilemma-ai-vs-human-decision-making.html" target='_blank' rel='noopener noreferrer'>The dilemma AI vs Human decision making</a> &nbsp; (2025-08-09)</li>
<br class="pagebreak">
<li><a href="https://robang74.github.io/roberto-a-foglietta/html/320-ragionare-non-e-come-fare-la-cacca.html" target='_blank' rel='noopener noreferrer'>Ragionare non è come fare la cacca!</a> &nbsp; (2025-06-08)</li>
<br class="pagebreak">
<li><a href="../il-problema-sei-tu-non-l-AI.md#" target='_blank' rel='noopener noreferrer'>Il problema sei tu, non l'AI</a> &nbsp; (2024-12-13)</li>
<p></p>
<br>
<p></p>
<H2 id="share-alike">Share alike</H2>
<p></p>
<p>&copy; 2025, <b>Roberto A. Foglietta</b> &lt;roberto.foglietta<span>&commat;</span>gmail.com&gt;, <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target='_blank' rel='noopener noreferrer'>CC BY-NC-ND 4.0</a></p>
<p></p>
</div>
<p></p>
<div id='date-legenda' align='center' translate='no' class='ghosted'><sub><hr></sub><sub><b>date legenda</b>: &#x2776; first draft publishing date or &#x2777; creation date in git, otherwise &#x2778; html creation page date. <u>&mapstoup;<a href='#' class='toplink' translate='no'>top</a>&mapstoup;</u></sub></div>
<br class='pagebreak'>
    </body>
</html>
