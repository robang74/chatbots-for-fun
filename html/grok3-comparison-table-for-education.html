<!DOCTYPE html>
<html>
    <head>
        <title>grok3-comparison-table-for-education</title>
        <meta charset='UTF-8'>
        <meta name='viewport' content='width=device-width, initial-scale=1.0'>
        <link rel='shortcut icon' type='image/x-icon' href='favicon.ico?'>
        <link rel='stylesheet' href='default.css'>
        <link rel='stylesheet' href='../intl/intlflg.css'>
        <!-- here begins the Javascript... why for the hell I got here? //-->
        <meta http-equiv='Content-Script-Type' content='text/javascript'>
        <link rel='stylesheet' href='ucustom.css' id='customStylesheet' media='screen'>
        <script>const cssdir='';</script note='global variable'>
        <script src='css-style-changer.js' defer></script>
        <link rel='stylesheet' href='printer.css' media='print'>
    </head>
    <body class=body>
<style>#printlink { display: inline; } @page { size: legal; margin: 0.50in 13.88mm 0.50in 13.88mm; zoom: 100%; } @media print { html { zoom: 100%; } }</style>
<p class='topbar'></p>
<div class='topbar' width='800px' translate='no'><b id='menu' onClick='nextStylesheet()'>&thinsp;&#9783;&thinsp;&Ropf;</b> &thinsp;&mdash;&thinsp; &#8543;&#8239;release: <b class='topbar'>2025-02-23&nbsp;<sup class='date-type topbar' id='datenote'>(&hairsp;<a href='#date-legenda' class='date-type topbar'>2</a>&hairsp;)</sup></b>  &thinsp;&mdash;&thinsp; rev.: <b class='topbar
'>8</b rev_num='
'> &thinsp;&mdash;&thinsp; transl.:&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/grok3-comparison-table-for-education?_x_tr_sl=en&_x_tr_tl=it&_x_tr_hl=it-IT&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>IT</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/grok3-comparison-table-for-education?_x_tr_sl=en&_x_tr_tl=de&_x_tr_hl=de-DE&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>DE</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/grok3-comparison-table-for-education?_x_tr_sl=en&_x_tr_tl=fr&_x_tr_hl=fr-FR&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>FR</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/grok3-comparison-table-for-education?_x_tr_sl=en&_x_tr_tl=es&_x_tr_hl=es-ES&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>ES</a> &thinsp;&mdash;&thinsp; goto:&nbsp; <a class='topbar' href='../index.html#index'>.&#x27F0;.</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='../../roberto-a-foglietta/index.html'target=_blank>RAF</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='../../chatgpt-answered-prompts/index.html'target=_blank>Q&A</a> <span id='printlink'>&thinsp;&mdash;&thinsp; <b>⎙</b>&hairsp;: <a aria-label='print this page' class='topbar' href='javascript:window.print()'>PDF</a></span>&nbsp;</div>
<div id="firstdiv">
<p class='topbar'></p>
<div align="center"><img class="wbsketch paleinv" src="../img/grok3-comparative-analysis.jpg" width="800"><br></div>
<p></p>
<H2 id="comparative-analysis-for-educational">Comparative analysis for educational<br><sup>provided by Grok3 + author's info box(es)</sup></H2>
<p></p>
<blockquote><span class="infoicon spanicon">&nbsp;<svg class="infoicon svgicon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path></svg><nobr class="alerts" translate="no">&nbsp;&nbsp;&middot;NOTICE&middot;&nbsp;&nbsp;</nobr></span><br><br>This document has been created by <a href="https://x.com/i/grok" target='_blank' rel='noopener noreferrer'>Grok3 AI</a> once initialized with the peer-review session prompt <a href="https://raw.githubusercontent.com/robang74/chatbots-for-fun/7607d8e2b4e24edad69fdd13a85d33144b8acc31/data/alex-peer-review-with-rag-v3.txt" target='_blank' rel='noopener noreferrer'>v3.4</a> to challenge the Nvidia Tesla K80 SW stack installation <a href="https://raw.githubusercontent.com/robang74/chatbots-for-fun/a068abbd2ae785f016409b1f4ef1c979ea9e469f/nvidia-sw-stack-installation-for-k80.md" target='_blank' rel='noopener noreferrer'>rev. 27</a> article and beyond. Providing the AI agent with information and links that I have collected about the used and refurbished PC desktop markets, I asked it to provide a comparison among different alternatives to the Esprimo P910 with Tesla K80 option, using my dual-system proposal as reference, rating them for practical use with AI workloads and educational purposes as DIY projects.</blockquote>
<p></p>
<li>This paper is part of the Esprimo P910 w/ Tesla K80 <a href="p910-k80-installation-manual-intro.html#" target='_blank' rel='noopener noreferrer'>installation manual</a> serie.</li>
<p></p>
Hello! I'm AleX, and I'll create a comprehensive comparison table for all the options you've suggested throughout our discussion. This includes your dual-system setup (P910 WS with GTX 1050 Ti + newer WS with Tesla K80), the Nvidia Shield pair, the recent Xbox (Series X), and the refurbished GTX 1050 Ti-equivalent WS, plus the higher-end refurbished WS with RTX 4060. The table will focus on key metrics for running a local AI agent with occasional training/fine-tuning: compute (CUDA cores, threads), memory (GPU and system RAM), cost-effectiveness (cores/€, MB/€), total cost, effort, and practical/educational ratings.
<p></p>
<hr>
<p></p>
<H3 id="criteria">Criteria</H3>
<p></p>
Educational value hinges on knowledge gained, skills taught, and insights offered, even in failure. I'll rate this as a "claim" of educational merit, aligned with the document's perspective (a learning journey), using [RTS]:
<p></p>
<li>100%: Universally valuable &mdash; teaches widely applicable skills and deep insights.</li>
<li>&nbsp 90%: Valuable with minor gaps &mdash; strong lessons, slight limits in scope.</li>
<li>&nbsp 75%: Plausible value &mdash; useful but unproven in broader impact.</li>
<li>&nbsp 50%: Mixed value &mdash; equal strengths and weaknesses.</li>
<li>&nbsp 25%: Limited value &mdash; minimal lessons, niche scope.</li>
<p></p>
<hr class="pagebreak">
<p></p>
<H3 id="comparison-table">Comparison table</H3>
<p></p>
<div class='center'><table id='table-001'><tr><th> Config </th><th> Cores </th><th> Thr </th><th> VRAM </th><th> RAM </th><th> Cost </th><th> Cores/€ </th><th> VRAM/€ </th><th> RAM/€ </th><th> Effort </th><th> Prct </th><th> Educ </th><th> Avg </th></tr>
<tr class='trline'><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td class='td1stcol'> Dual-System WS/SRV </td><td> 5800 </td><td> 10 </td><td> 28GB </td><td> 48GB </td><td> €&nbsp;498 </td><td> 11.65 </td><td> &nbsp;57.43 </td><td> 98.80 </td><td> Medium </td><td> 90% </td><td> 95% </td><td> 92% </td></tr>
<tr><td class='td1stcol'> P910 with K80 </td><td> 4992 </td><td> &nbsp;4 </td><td> 24GB </td><td> 16GB </td><td> €&nbsp;190 </td><td> 26.27 </td><td> 129.49 </td><td> 86.23 </td><td> Medium </td><td> 75% </td><td> 90% </td><td> 83% </td></tr>
<tr><td class='td1stcol'> 2x Nvidia Shield </td><td> &nbsp;&nbsp;&nbsp;0 </td><td> &nbsp;8 </td><td> &nbsp;2GB </td><td> &nbsp;6GB </td><td> €&nbsp;400 </td><td> &nbsp;0.00 </td><td> &nbsp;&nbsp;5.12 </td><td> 15.36 </td><td> High </td><td> 25% </td><td> 50% </td><td> 38% </td></tr>
<tr><td class='td1stcol'> Xbox Series X </td><td> &nbsp;&nbsp;&nbsp;0 </td><td> 16 </td><td> 10GB </td><td> 16GB </td><td> €&nbsp;500 </td><td> &nbsp;0.00 </td><td> &nbsp;20.48 </td><td> 32.77 </td><td> High </td><td> 25% </td><td> 50% </td><td> 38% </td></tr>
<tr><td class='td1stcol'> Refurb GTX 1050 Ti </td><td> &nbsp;768 </td><td> 12 </td><td> &nbsp;4GB </td><td> 16GB </td><td> €&nbsp;799 </td><td> &nbsp;0.96 </td><td> &nbsp;&nbsp;5.12 </td><td> 20.48 </td><td> Low </td><td> 50% </td><td> 75% </td><td> 63% </td></tr>
<tr><td class='td1stcol'> Refurb RTX 4060 </td><td> 3072 </td><td> 16 </td><td> &nbsp;8GB </td><td> 32GB </td><td> €1100 </td><td> &nbsp;2.79 </td><td> &nbsp;&nbsp;7.44 </td><td> 29.80 </td><td> Low </td><td> 75% </td><td> 75% </td><td> 75% </td></tr>
</table>
</div><p></p>
<H4>Notes</H4>
<p></p>
<li class='numli'><b>1.&emsp;</b><b>Dual-System Cost</b>: €408 (WS €147 + SRV €261) + €90 (accessories & used monitor) = €498.</li>
<li class='li2in'><b>WS</b>: Fujitsu Esprimo P910 E85+ with Intel i5-3470 + Nvidia GTX 1050 Ti 4GB onboard; </li>
<li class='li2in'><b>SRV</b>: 2016/2018 Workstation (Intel i5-6500/8500, 4/8 threads) + Nvidia Tesla K80.</li>
<li class='li2in'><b>Effort</b>: most of the effort includes PCIe compatibility hacks and K80 setup.</li>
<p></p>
<li class='numli'><b>2.&emsp;</b><b>Non-CUDA Systems</b>: Nvidia Shield and Xbox lack native CUDA support.</li>
<li class='li2in'><b>Shield Hardware</b>: 2x Nvidia Shield devices with Tegra X1</li>
<li class='li3in'>Maxwell GPU, 256 cores, ~0.5 TFLOPS each), no CUDA support.</li>
<li class='li2in'><b>Xbox Hardware</b>: Xbox Series X with Zen 2 CPU and RDNA 2 GPU</li>
<li class='li3in'>c.a. 12 TFLOPS FP32 need hacks (e.g., ROCm), unproven for AI.</li>
<li class='li2in'><b>Effort</b>: high effort due to Linux and AI conversion hacks.</li>
<p></p>
<li class='numli'><b>3.&emsp;</b><b>Xbox Memory</b>: 16GB GDDR6 shared, 10GB usable for GPU at 560GB/s.</li>
<p></p>
<li class='numli'><b>4.&emsp;</b><b>Refurb RTX 4060 Cost</b>: €1200 - €100 (1TB SSD value) = €1100 tower only.</li>
<li class='li2in'><b>Hardware</b>: e.g., Dell Precision 3660 with Intel i7-12700 + Nvidia RTX 4060.</li>
<li class='li2in'><b>Effort</b>: low effort &mdash; plug-and-play setup.</li>
<p></p>
<li class='numli'><b>5.&emsp;</b><b>MB Calculations</b>: GPU/System RAM in MB (GB x 1024) ÷ cost in €.</li>
<li class='li2in'><b>Refurb GTX 1050 Ti Hardware</b>: e.g., Dell OptiPlex 7060 with Intel i5-8500.</li>
<li class='li2in'><b>Effort</b>: low effort &mdash; plug-and-play setup.</li>
<p></p>
<hr>
<p></p>
<H3 id="key-metrics">Key metrics</H3>
<p></p>
<li><b>CUDA Cores</b>: Total GPU compute units for AI (training/inference).</li>
<li><b>Threads</b>: CPU threads for parallel tasks.</li>
<li><b>GPU RAM</b>: Total graphics memory for models/datasets.</li>
<li><b>System RAM</b>: Total memory for OS/data handling.</li>
<li><b>Total Cost</b>: Full price including peripherals or tower-only for refurbs.</li>
<li><b>Cores/€</b>: CUDA cores per euro (shaders/€ for Xbox).</li>
<li><b>GPU MB/€</b>: GPU RAM in MB per euro.</li>
<li><b>Sys MB/€</b>: System RAM in MB per euro.</li>
<li><b>Effort</b>: Setup complexity/risk.</li>
<li><b>Ratings</b>: from prior analyses</li>
<li class='li2in'>Practical about AI performance,</li>
<li class='li2in'>Educational about learning value.</li>
<p></p>
<hr class="pagebreak">
<p></p>
<H3 id="analysis">Analysis</H3>
<p></p>
Analysis of the various options as alternatives
<p></p>
<H4>Dual-System (€498)</H4>
<p></p>
<li><b>Strengths</b>: 5800 CUDA cores, 28GB GPU RAM, 48GB system RAM, 8-12 threads,</li>
<li class='li2in'>WS (1050 Ti) runs inference/RAG on Ubuntu 24.04,</li>
<li class='li2in'>Server (K80) trains on ≤20.04 with 24GB,</li>
<li class='li2in'>Gigabit Ethernet ties it together.</li>
<li><b>Weakness</b>: Moderate effort P910 PCIe 75W install + K80 dual-PSU setup.</li>
<li><b>Edge</b>: Crushes all options in cost-effectiveness, memory, and AI training potential.</li>
<p></p>
<H4>2x Nvidia Shield (€400)</H4>
<p></p>
<li><b>Strengths</b>: Compact, €400 for dual-unit potential.</li>
<li><b>Weaknesses</b>: No CUDA, 2GB GPU RAM total,</li>
<li class='li2in'>high effort (Linux hacks unproven).</li>
<li class='li2in'>Can't handle AI training or large models.</li>
<li><b>Edge</b>: None for AI &mdash; gaming/entertainment focus.</li>
<p></p>
<H4>Xbox Series X (€500)</H4>
<p></p>
<li><b>Strengths</b>: 12 TFLOPS FP32, 16 threads, 10GB RAM, €500 with peripherals.</li>
<li><b>Weaknesses</b>: No CUDA, high-effort Linux/AI hacks, 10GB limits training vs. 28GB.</li>
<li><b>Edge</b>: Raw compute, but AI-unfriendly.</li>
<p></p>
<H4>Refurb GTX 1050 Ti WS (€799)</H4>
<p></p>
<li><b>Strengths</b>: 768 cores, 12 threads, plug-and-play, Ubuntu 24.04-ready.</li>
<li><b>Weaknesses</b>: 4GB GPU RAM, €799 costly for specs.</li>
<li><b>Edge</b>: Safe, modest inference, no training heft.</li>
<p></p>
<H4>Refurb RTX 4060 WS (€1100)</H4>
<p></p>
<li><b>Strengths</b>: 3072 cores (15 TFLOPS FP32), 16 threads, 8GB GPU RAM</li>
<li class='li2in'>modern CUDA 11.7, zero effort.</li>
<li><b>Weaknesses</b>: €1100 for 2.79 cores/€, 8GB caps training vs. 28GB.</li>
<li><b>Edge</b>: Reliable, mid-tier AI, pricey.</li>
<p></p>
<div class="pagebreak"><br></div>
<p></p>
<H2 id="conclusion">Conclusion</H2>
<p></p>
<li><b>Dual-System (€498)</b>: Unbeatable </li>
<li class='li2in'>11.65 cores/€, 57.43MB GPU RAM/€, 98.8MB system RAM/€, 8 or 12 threads.</li>
<li class='li2in'>Outperforms €1100 WS for AI training/inference.</li>
<li class='li2in'>Educationally rich (WS/server split, K80 history).</li>
<li class='li2in'>Installation effert is minor vs. gains.</li>
<p></p>
<li><b>Others</b>: Shield/Xbox flounder (no CUDA, low RAM),</li>
<li class='li2in'>refurbs lag (costly, less memory/core power).</li>
<p></p>
<H3 id="broader-impact">Broader Impact</H3>
<p></p>
<li><b>Educational</b>: 90% &mdash; mid-skilled goldmine: Linux, AI, refurbished, tech-tweaks.</li>
<p></p>
<li><b>Practicality</b>: 75%-90% &mdash; range hinges on serial/AMT "Above 4GB decoding" outcome.</li>
<p></p>
<li><b>Social spotlight</b>: 90% &mdash; ecological HW re-use, budget AI story social-media ready.</li>
<p></p>
<br>
<p></p>
<H2 id="share-alike">Share alike</H2>
<p></p>
<p>&copy; 2025, <b>Roberto A. Foglietta</b> &lt;roberto.foglietta<span>&commat;</span>gmail.com&gt;, <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target='_blank' rel='noopener noreferrer'>CC BY-NC-ND 4.0</a></p>
<p></p>
</div>
<p></p>
<div id='date-legenda' align='center' translate='no'><sub><hr></sub><sub><b>date legenda</b>: &#x2776; first draft publishing date or &#x2777; creation date in git, otherwise &#x2778; html creation page date. <u>&mapstoup;<a href='#' class='toplink' translate='no'>top</a>&mapstoup;</u></sub></div>
<br class='pagebreak'>
    </body>
</html>
