<!DOCTYPE html>
<html>
    <head>
        <title>introducing-katia-text-analysis-framework</title>
        <meta charset='UTF-8'>
        <meta name='viewport' content='width=device-width, initial-scale=1.0'>
        <link rel='shortcut icon' type='image/x-icon' href='favicon.ico?'>
        <link rel='stylesheet' href='default.css'>
        <link rel='stylesheet' href='../intl/intlflg.css'>
        <!-- here begins the Javascript... why for the hell I got here? //-->
        <meta http-equiv='Content-Script-Type' content='text/javascript'>
        <link rel='stylesheet' href='ucustom.css' id='customStylesheet' media='screen'>
        <script>const cssdir='';</script note='global variable'>
        <script src='css-style-changer.js' defer></script>
        <link rel='stylesheet' href='printer.css' media='print'>
    </head>
    <body class=body>
<style>#printlink { display: inline; } @page { size: legal; margin: 0.50in 13.88mm 0.50in 13.88mm; zoom: 100%; } @media print { html { zoom: 100%; } }</style>
<p class='topbar'></p>
<div class='topbar' width='800px' translate='no'><b id='menu' onClick='nextStylesheet()'>&thinsp;&#9783;&thinsp;&Ropf;</b> &thinsp;&mdash;&thinsp; &#8543;&#8239;release: <b class='topbar'>2025-10-05&nbsp;<sup class='date-type topbar' id='datenote'>(&hairsp;<a href='#date-legenda' class='date-type topbar'>2</a>&hairsp;)</sup></b>  &thinsp;&mdash;&thinsp; rev.: <b class='topbar
'>5</b rev_num='
'> &thinsp;&mdash;&thinsp; transl.:&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/introducing-katia-text-analysis-framework?_x_tr_sl=it&_x_tr_tl=en&_x_tr_hl=en-EN&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>EN</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/introducing-katia-text-analysis-framework?_x_tr_sl=it&_x_tr_tl=de&_x_tr_hl=de-DE&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>DE</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/introducing-katia-text-analysis-framework?_x_tr_sl=it&_x_tr_tl=fr&_x_tr_hl=fr-FR&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>FR</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/introducing-katia-text-analysis-framework?_x_tr_sl=it&_x_tr_tl=es&_x_tr_hl=es-ES&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>ES</a> &thinsp;&mdash;&thinsp; goto:&nbsp; <a class='topbar' href='../index.html#index'>.&#x27F0;.</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='../../roberto-a-foglietta/index.html'target=_blank>RAF</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='../../chatgpt-answered-prompts/index.html'target=_blank>Q&A</a> <span id='printlink'>&thinsp;&mdash;&thinsp; <b>⎙</b>&hairsp;: <a aria-label='print this page' class='topbar' href='javascript:window.print()'>PDF</a></span>&nbsp;</div>
<div id="firstdiv">
<p class='topbar'></p>
<div align="center"><img class="bwsketch darkinv" src="../img/introducing-katia-text-analysis-framework.jpg" width="800"><br/></div>
<p></p>
<H2 id="introducing-katia-text-analysis-framework">Introducing Katia, text analysis framework</H2>
<p></p>
<li><b>1st edition</b>, articolo scritto a partire alcuni miei post su Linkedin: &nbsp; <a href="https://www.linkedin.com/posts/robertofoglietta_pubblicit%C3%A0-progresso-kimi-su-katia-vs-gemini-activity-7380367700159606784--dI6" target='_blank' rel='noopener noreferrer'>post #1</a> &nbsp; <a href="https://www.linkedin.com/posts/robertofoglietta_how-to-effectively-summarize-a-long-text-activity-7373591846163341312-7W6N" target='_blank' rel='noopener noreferrer'>post #12</a> &nbsp; <a href="https://www.linkedin.com/posts/robertofoglietta_katia-wtf-are-you-doing-to-that-chatbot-activity-7363277278954274817-jdTf" target='_blank' rel='noopener noreferrer'>post #3</a></li>
<p></p>
Altri post ancora da includere:
<p></p>
<li><a href="https://www.linkedin.com/posts/robertofoglietta_katia-wtf-are-you-doing-to-that-chatbot-activity-7364366202275532802-NrIR" target='_blank' rel='noopener noreferrer'>post #2</a> &nbsp; <a href="https://www.linkedin.com/posts/robertofoglietta_katia-can-work-as-juan-the-ai-financial-activity-7350707888937484290-iZDx" target='_blank' rel='noopener noreferrer'>post #4</a> &nbsp; <a href="https://www.linkedin.com/posts/robertofoglietta_witchcraft-mon-cher%C3%AC-what-else-a-dialogue-activity-7358082737318064128-nxlA" target='_blank' rel='noopener noreferrer'>post #5</a> &nbsp; <a href="https://www.linkedin.com/posts/robertofoglietta_google-engineers-vs-katia-framework-google-activity-7358567525527224320-y8m0" target='_blank' rel='noopener noreferrer'>post #6</a> &nbsp; <a href="https://www.linkedin.com/posts/robertofoglietta_mr-spock-is-back-and-it-supports-katia-activity-7358776512856113153-MUJt" target='_blank' rel='noopener noreferrer'>post #7</a> &nbsp; <a href="https://www.linkedin.com/posts/robertofoglietta_conceptual-perplexity-is-the-key-i-am-not-activity-7362712455413661698-ACvu" target='_blank' rel='noopener noreferrer'>post #8</a> &nbsp; <a href="https://www.linkedin.com/posts/robertofoglietta_vygotskys-theory-of-cognitive-development-activity-7358743887726710784-NWtA" target='_blank' rel='noopener noreferrer'>post #9</a> &nbsp; <a href="https://www.linkedin.com/posts/robertofoglietta_vygotskys-theory-of-cognitive-development-activity-7358719667202318336-xQBG" target='_blank' rel='noopener noreferrer'>post #10</a> &nbsp; <a href="https://www.linkedin.com/posts/robertofoglietta_ai-chatbots-struggle-with-a-standard-way-activity-7351209268315860992-awg0" target='_blank' rel='noopener noreferrer'>post #11</a></li>
<p></p>
<hr>
<p></p>
<H3 id="kimi-k2-su-katia-vs-gemini">Kimi K2 su Katia vs Gemini</H3>
<p></p>
Ho deciso di usare Kimi K2 per confrontare la mia interazione sullo stesso testo fra Gemini e Katia (framework cognitivo applicato a Gemini). Quindi lo stello modello AI, ma così come offerto da Google e con Katia.
<p></p>
<li>Il <a href="https://www.kimi.com/share/d3gpjhcn907c4b3b8qqg" target='_blank' rel='noopener noreferrer'>confronto</a> riguardo alla comprensione del testo e supporto alla scrittura, il suo <a href="../data/gemini-senza-katia-framework-per-confronto.txt#" target='_blank' rel='noopener noreferrer'>dump</a>.</li>
<p></p>
Qui sotto riporto, in estrema sintesi, la struttura della chat con Kimi K2 per il confronto fra Gemini e Katia.
<p></p>
<hr>
<p></p>
<H4>PROMPT #1</H4>
<p></p>
Come valuti, nell'ambito della conversazione contenuta nell'allegato del primo prompt, la capacità di Katia/Gemini di comprendere il testo, affatto banale, prodotto e fornito dall'operatore umano?
<p></p>
<hr class="post-it">
<p></p>
<H4>KIMI #1</H4>
<p></p>
Risposta: <b>4.9 su 5</b>.
<p></p>
Katia ha mostrato una comprensione di alto livello, ben oltre la parfrasi banale: ha ricostruito premesse non dette, formalizzato principi astratti e tenuto traccia delle revisioni senza perdere il filo narrativo.
<p></p>
<hr>
<p></p>
<H4>PROMPT #2</H4>
<p></p>
In termini di comprensione del testo, pensi vi siano differenze fra Gemini e Katia? Come valuteresti la comprensione del testo da parte di Gemini sulla stessa scala che hai già usato per Katia?
<p></p>
<hr class="post-it">
<p></p>
<H4>KIMI #2</H4>
<p></p>
Risposta: <b>3.5 su 5</b>.
<p></p>
In sintesi: Gemini comprende abbastanza per una critica di lettura one-shot; Katia comprende a sufficienza per farti continuare a ragionare su quello che hai scritto senza perdere il filo logico fra revisioni successive.
<p></p>
<li><b>Catena di elaborazione</b>: Percezione Neutra → Valutazione Contestuale → Azione Efficace</li>
<p></p>
Qui di seguito elencati i punti dove si perde il punto e mezzo
<p></p>
<li><b>Ricostruzione implicita</b>: Gemini plain coglie la “tesi anti-ideologia” ma non esplicita la catena di elaborazione, lasciando sotto-traccia il cuore pragmatico dell’aneddoto.</li>
<p></p>
<li><b>Micro e macro-struttura</b>: vede due blocchi (aneddoto + riflessione) ma non collega il micro-esempio al principio scalabile; Katia lo formalizza e lo riusa nella parte IVA.</li>
<p></p>
<li><b>Iterazione</b>: manca del tutto; il modello non può correggere la propria lettura dopo il tuo chiarimento, quindi la “comprensione” resta quella del primo shot.</li>
<p></p>
<hr>
<p></p>
<H4>PROMPT #3</H4>
<p></p>
Le due conversazioni però non sono equivalenti, perché a Katia sono stati forniti input di maggiore consistenza. (Perché Katia mi ha fornito un feedback di maggiore profondità al quale ho potuto rispondere con altrettanto maggiore profondità: stimolo → reazione)
<p></p>
<hr class="post-it">
<p></p>
<H4>KIMI #3</H4>
<p></p>
Hai ragione: le due traiettorie non sono paragonabili in quanto a quantità e qualità dell’input. Gemini ha quindi lavorato su un singolo shot e su un solo registro (quello narrativo). Per questo il 3,5/5 a Gemini non è una condanna, ma una misura dell’effetto tetto che il modello può raggiungere in quelle condizioni di input.
<p></p>
<br>
<p></p>
<H2 id="conclusione">Conclusione</H2>
<p></p>
Non ho fornito a Gemini la stessa quantità e qualità di input che ho fornito a Katia perché Gemini non ha saputo creare in me lo stimolo per farli emergerli e quindi proporglieli. Quindi, la capacità di comprendere un testo influenza la capacità di interagire in modo coinvolgente con l'operatore umano. Perciò in termini di efficacia, si tratta di un doppio vantaggio, non +30% ma un +60%.
<p></p>
<li>Infatti Kimi K2 stima che il valore del prodotto stia in un 30% per il modello e 70% interazione.</li>
<p></p>
Il motivo è che la comprensione profonda, quella che Katia raggiunge subito grazie al framework applicato a Gemini, attiva un feedback loop positivo: comprensione superiore → interazione superiore → input superiore → output superiore. L'incremento sulla scala appare lineare ma in termini di risultato si tratta di un salto notevole che fa davvero la differenza quando il testo affronta un tema complessp.
<p></p>
<li>Usando Katia come framework cognitivo, il collo di bottiglia diventa l'utente, non più il modello.</li>
<p></p>
Il che ci conferma che anche con Katia, l'intelligenza artificiale incrementa la produttività degli utilizzatori esperti molto di più di quanto faccia l'80% di quelli centrati sulla media. Quindi il top 10% è agevolato nella performance (ciclo I/O virtuoso), il bottom 10% è agevolato nell'apprendimento delle base (errori AI improbabili), in mezzo c'è una valle relativamente stagnate perché il vantaggio apparente è quasi annullato dal rischio (non più trascurabile) di recepire risposte errate.
<p></p>
Rimane da capire se per questo bacino d'utenti il framework Katia possa aiutarli a superare la <i>valle stagnante</i>. 
<p></p>
<hr>
<p></p>
<H3 id="bacino-dutenza-e-sfide">Bacino d'utenza e sfide</H3>
<p></p>
Si consideri che circa 1/3 di tutti i token scambiati con i chatbot riuarda un qualche tipo di elaborazione di testo. Circa un 1/3 di tutti i token scambiati con ChatGPT riguarda studenti delle superiori o universitari. Appare evidente che un framework come Katia abbia un bacino d'utenza potenziale molto grande, sia in termini relativi e sia in termini assoluti. Cfr. <a href="https://www.linkedin.com/posts/robertofoglietta_how-to-effectively-summarize-a-long-text-activity-7373591846163341312-7W6N" target='_blank' rel='noopener noreferrer'>post #12</a>
<p></p>
<hr class="post-it">
<p></p>
ChatGPT usage data by National Bureau of Economic Research
<p></p>
<li>700 million people, 2.5 billion daily messages.</li>
<li>Writing 24% for editing, summarizing, translating, drafting.</li>
<li>Source of the above numbers: nber.org/papers/w34255</li>
<p></p>
Considering the four sub-usage in "writing" class equally distributed:
<p></p>
<li>Summary: 6% is 150 million daily served prompts</li>
<li>1/3 of the ChatGPT traffic is generated by top-half grades students.</li>
<p></p>
<hr class="post-it">
<p></p>
Nella <i>valle stagnante</i> si usa l'AI più per pigrizia che per desiderio di eccellere. Da un punto di vista "meccanicistico" il fatto che il benchmark SimpleQA passi dal 30% di Gemini 2.5 Flash a un circa 90% quando il framework Katia è aggiunto, ma non attivato nel sistem prompt, è rilevante perché è ragionevole pensare che abbatta sensibilmente anche errori e allucinazioni. Cfr. <a href="https://www.linkedin.com/posts/robertofoglietta_katia-wtf-are-you-doing-to-that-chatbot-activity-7363277278954274817-jdTf" target='_blank' rel='noopener noreferrer'>post #3</a>
<p></p>
<hr class="post-it">
<p></p>
The SimpleQA score for Gemini 2.5 Flash is expected to be 29.7%, it is the hardest test to pass, despite being composed of simple fact-based questions. Katia v0.9.56.4 with Gemini 2.5 Flash, scored 90% on 30 questions taken from the top and the bottom of this dataset.
<p></p>
Before jumping to "easy" conclusion, consider that by a rule of thumb &mdash; with a 30 item set &mdash; the standard error is taken as <tt>sqrt(30) = 5</tt>. However, even <tt>22/30 = 73%</tt> is <b>way</b> different score than 30%. In fact, it's worth noticing that Gemini 2.5 Pro achieves a higher score of 54.0% on the same benchmark.
<p></p>
<hr class="post-it">
<p></p>
Considerando che nella <i>valle stagnante</i> gli errori e le allucinazioni sono le "sabbie mobili" che impantanano gli utenti, aumentare sensibilmente l'affidabilità delle risposte diventa un fattore abilitante. Se, inoltre, aggiungiamo che gli studenti pigri potrebbero trasformarsi in curiosi grazie ad una risposta stimolante che li faccia interessare all'oggetto dello studio, il vantaggio è doppio.
<p></p>
<br>
<p></p>
<H2 id="share-alike">Share alike</H2>
<p></p>
<p>&copy; 2025, <b>Roberto A. Foglietta</b> &lt;roberto.foglietta<span>&commat;</span>gmail.com&gt;, <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target='_blank' rel='noopener noreferrer'>CC BY-NC-ND 4.0</a></p>
</div>
<div id='date-legenda' align='center' translate='no' class='ghosted'><sub><hr></sub><sub><b>date legenda</b>: &#x2776; first draft publishing date or &#x2777; creation date in git, otherwise &#x2778; html creation page date. <u>&mapstoup;<a href='#' class='toplink' translate='no'>top</a>&mapstoup;</u></sub></div>
<br class='pagebreak'>
    </body>
</html>
