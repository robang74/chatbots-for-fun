<!DOCTYPE html>
<html>
    <head>
        <title>introducing-katia-text-analysis-framework</title>
        <meta charset='UTF-8'>
        <meta name='viewport' content='width=device-width, initial-scale=1.0'>
        <link rel='shortcut icon' type='image/x-icon' href='favicon.ico?'>
        <link rel='stylesheet' href='default.css'>
        <link rel='stylesheet' href='../intl/intlflg.css'>
        <!-- here begins the Javascript... why for the hell I got here? //-->
        <meta http-equiv='Content-Script-Type' content='text/javascript'>
        <link rel='stylesheet' href='ucustom.css' id='customStylesheet' media='screen'>
        <script>const cssdir='';</script note='global variable'>
        <script src='css-style-changer.js' defer></script>
        <link rel='stylesheet' href='printer.css' media='print'>
    </head>
    <body class=body>
<style>#printlink { display: inline; } @page { size: legal; margin: 0.50in 13.88mm 0.50in 13.88mm; zoom: 100%; } @media print { html { zoom: 100%; } }</style>
<p class='topbar'></p>
<div class='topbar' width='800px' translate='no'><b id='menu' onClick='nextStylesheet()'>&thinsp;&#9783;&thinsp;&Ropf;</b> &thinsp;&mdash;&thinsp; &#8543;&#8239;release: <b class='topbar'>2025-10-05&nbsp;<sup class='date-type topbar' id='datenote'>(&hairsp;<a href='#date-legenda' class='date-type topbar'>2</a>&hairsp;)</sup></b>  &thinsp;&mdash;&thinsp; rev.: <b class='topbar
'>8</b rev_num='
'> &thinsp;&mdash;&thinsp; transl.:&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/introducing-katia-text-analysis-framework?_x_tr_sl=it&_x_tr_tl=en&_x_tr_hl=en-EN&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>EN</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/introducing-katia-text-analysis-framework?_x_tr_sl=it&_x_tr_tl=de&_x_tr_hl=de-DE&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>DE</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/introducing-katia-text-analysis-framework?_x_tr_sl=it&_x_tr_tl=fr&_x_tr_hl=fr-FR&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>FR</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/introducing-katia-text-analysis-framework?_x_tr_sl=it&_x_tr_tl=es&_x_tr_hl=es-ES&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>ES</a> &thinsp;&mdash;&thinsp; goto:&nbsp; <a class='topbar' href='../index.html#index'>.&#x27F0;.</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='../../roberto-a-foglietta/index.html'target=_blank>RAF</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='../../chatgpt-answered-prompts/index.html'target=_blank>Q&A</a> <span id='printlink'>&thinsp;&mdash;&thinsp; <b>⎙</b>&hairsp;: <a aria-label='print this page' class='topbar' href='javascript:window.print()'>PDF</a></span>&nbsp;</div>
<div id="firstdiv">
<p class='topbar'></p>
<div align="center"><img class="bwsketch darkinv" src="../img/introducing-katia-text-analysis-framework.jpg" width="800"><br/></div>
<p></p>
<H2 id="introducing-katia-text-analysis-framework">Introducing Katia, text analysis framework</H2>
<p></p>
<li><b>1st edition</b>, articolo scritto a partire alcuni miei post su Linkedin: &nbsp; <a href="https://www.linkedin.com/posts/robertofoglietta_pubblicit%C3%A0-progresso-kimi-su-katia-vs-gemini-activity-7380367700159606784--dI6" target='_blank' rel='noopener noreferrer'>post #1</a> &nbsp; <a href="https://www.linkedin.com/posts/robertofoglietta_how-to-effectively-summarize-a-long-text-activity-7373591846163341312-7W6N" target='_blank' rel='noopener noreferrer'>post #12</a> &nbsp; <a href="https://www.linkedin.com/posts/robertofoglietta_katia-wtf-are-you-doing-to-that-chatbot-activity-7363277278954274817-jdTf" target='_blank' rel='noopener noreferrer'>post #3</a></li>
<p></p>
Altri post ancora da includere:
<p></p>
<li><a href="https://www.linkedin.com/posts/robertofoglietta_katia-wtf-are-you-doing-to-that-chatbot-activity-7364366202275532802-NrIR" target='_blank' rel='noopener noreferrer'>post #2</a> &nbsp; <a href="https://www.linkedin.com/posts/robertofoglietta_katia-can-work-as-juan-the-ai-financial-activity-7350707888937484290-iZDx" target='_blank' rel='noopener noreferrer'>post #4</a> &nbsp; <a href="https://www.linkedin.com/posts/robertofoglietta_witchcraft-mon-cher%C3%AC-what-else-a-dialogue-activity-7358082737318064128-nxlA" target='_blank' rel='noopener noreferrer'>post #5</a> &nbsp; <a href="https://www.linkedin.com/posts/robertofoglietta_google-engineers-vs-katia-framework-google-activity-7358567525527224320-y8m0" target='_blank' rel='noopener noreferrer'>post #6</a> &nbsp; <a href="https://www.linkedin.com/posts/robertofoglietta_mr-spock-is-back-and-it-supports-katia-activity-7358776512856113153-MUJt" target='_blank' rel='noopener noreferrer'>post #7</a> &nbsp; <a href="https://www.linkedin.com/posts/robertofoglietta_conceptual-perplexity-is-the-key-i-am-not-activity-7362712455413661698-ACvu" target='_blank' rel='noopener noreferrer'>post #8</a> &nbsp; <a href="https://www.linkedin.com/posts/robertofoglietta_vygotskys-theory-of-cognitive-development-activity-7358743887726710784-NWtA" target='_blank' rel='noopener noreferrer'>post #9</a> &nbsp; <a href="https://www.linkedin.com/posts/robertofoglietta_vygotskys-theory-of-cognitive-development-activity-7358719667202318336-xQBG" target='_blank' rel='noopener noreferrer'>post #10</a> &nbsp; <a href="https://www.linkedin.com/posts/robertofoglietta_ai-chatbots-struggle-with-a-standard-way-activity-7351209268315860992-awg0" target='_blank' rel='noopener noreferrer'>post #11</a></li>
<p></p>
<hr>
<p></p>
<H3 id="kimi-k2-su-katia-vs-gemini">Kimi K2 su Katia vs Gemini</H3>
<p></p>
Ho deciso di usare Kimi K2 per confrontare la mia interazione sullo stesso testo fra Gemini e Katia (framework cognitivo applicato a Gemini). Quindi lo stello modello AI, ma così come offerto da Google e con Katia.
<p></p>
<li>Il <a href="https://www.kimi.com/share/d3gpjhcn907c4b3b8qqg" target='_blank' rel='noopener noreferrer'>confronto</a> riguardo alla comprensione del testo e supporto alla scrittura, i suoi <a href="https://robang74.github.io/roberto-a-foglietta/data/340-valutazione-di-kimi-su-katia.txt#" target='_blank' rel='noopener noreferrer' target='_blank' rel='noopener noreferrer'>dump #1</a> &nbsp;<a href="../data/kimi-k2-confronto-gemini-vs-con-katia.txt#" target='_blank' rel='noopener noreferrer'>dump #2</a>.</li>
<p></p>
Qui sotto riporto, in estrema sintesi, la struttura della chat con Kimi K2 per il confronto fra <a href="../data/gemini-senza-katia-framework-per-confronto.txt#" target='_blank' rel='noopener noreferrer'>Gemini</a> e <a href="https://robang74.github.io/roberto-a-foglietta/data/340-riciclare-plastica-e-anti-economico-zero-iva-katia.txt#" target='_blank' rel='noopener noreferrer' target='_blank' rel='noopener noreferrer'>Katia</a>.
<p></p>
<hr>
<p></p>
<H4>PROMPT #1</H4>
<p></p>
Come valuti, nell'ambito della conversazione contenuta nell'allegato del primo prompt, la capacità di Katia/Gemini di comprendere il testo, affatto banale, prodotto e fornito dall'operatore umano?
<p></p>
<hr class="post-it">
<p></p>
<H4>KIMI #1</H4>
<p></p>
Risposta: <b>4.9 su 5</b>.
<p></p>
Katia ha mostrato una comprensione di alto livello, ben oltre la parfrasi banale: ha ricostruito premesse non dette, formalizzato principi astratti e tenuto traccia delle revisioni senza perdere il filo narrativo.
<p></p>
<hr>
<p></p>
<H4>PROMPT #2</H4>
<p></p>
In termini di comprensione del testo, pensi vi siano differenze fra Gemini e Katia? Come valuteresti la comprensione del testo da parte di Gemini sulla stessa scala che hai già usato per Katia?
<p></p>
<hr class="post-it">
<p></p>
<H4>KIMI #2</H4>
<p></p>
Risposta: <b>3.5 su 5</b>.
<p></p>
In sintesi: Gemini comprende abbastanza per una critica di lettura one-shot; Katia comprende a sufficienza per farti continuare a ragionare su quello che hai scritto senza perdere il filo logico fra revisioni successive.
<p></p>
<li><b>Catena di elaborazione</b>: Percezione Neutra → Valutazione Contestuale → Azione Efficace</li>
<p></p>
Qui di seguito elencati i punti dove si perde il punto e mezzo
<p></p>
<li><b>Ricostruzione implicita</b>: Gemini plain coglie la “tesi anti-ideologia” ma non esplicita la catena di elaborazione, lasciando sotto-traccia il cuore pragmatico dell’aneddoto.</li>
<p></p>
<li><b>Micro e macro-struttura</b>: vede due blocchi (aneddoto + riflessione) ma non collega il micro-esempio al principio scalabile; Katia lo formalizza e lo riusa nella parte IVA.</li>
<p></p>
<li><b>Iterazione</b>: manca del tutto; il modello non può correggere la propria lettura dopo il tuo chiarimento, quindi la “comprensione” resta quella del primo shot.</li>
<p></p>
<hr>
<p></p>
<H4>PROMPT #3</H4>
<p></p>
Le due conversazioni però non sono equivalenti, perché a Katia sono stati forniti input di maggiore consistenza. (Perché Katia mi ha fornito un feedback di maggiore profondità al quale ho potuto rispondere con altrettanto maggiore profondità: stimolo → reazione)
<p></p>
<hr class="post-it">
<p></p>
<H4>KIMI #3</H4>
<p></p>
Hai ragione: le due traiettorie non sono paragonabili in quanto a quantità e qualità dell’input. Gemini ha quindi lavorato su un singolo shot e su un solo registro (quello narrativo). Per questo il 3,5/5 a Gemini non è una condanna, ma una misura dell’effetto tetto che il modello può raggiungere in quelle condizioni di input.
<p></p>
<br>
<p></p>
<H2 id="conclusione">Conclusione</H2>
<p></p>
Non ho fornito a Gemini la stessa quantità e qualità di input che ho fornito a Katia perché Gemini non ha saputo creare in me lo stimolo per farli emergerli e quindi proporglieli. Quindi, la capacità di comprendere un testo influenza la capacità di interagire in modo coinvolgente con l'operatore umano. Perciò in termini di efficacia, si tratta di un doppio vantaggio, non +30% ma un +60%.
<p></p>
<li>Infatti Kimi K2 stima che il valore del prodotto stia in un 30% per il modello e 70% interazione.</li>
<p></p>
Il motivo è che la comprensione profonda, quella che Katia raggiunge subito grazie al framework applicato a Gemini, attiva un feedback loop positivo: comprensione superiore → interazione superiore → input superiore → output superiore. L'incremento sulla scala appare lineare ma in termini di risultato si tratta di un salto notevole che fa davvero la differenza quando il testo affronta un tema complessp.
<p></p>
<li>Usando Katia come framework cognitivo, il collo di bottiglia diventa l'utente, non più il modello.</li>
<p></p>
Il che ci conferma che anche con Katia, l'intelligenza artificiale incrementa la produttività degli utilizzatori esperti molto di più di quanto faccia l'80% di quelli centrati sulla media. Quindi il top 10% è agevolato nella performance (ciclo I/O virtuoso), il bottom 10% è agevolato nell'apprendimento delle base (errori AI improbabili), in mezzo c'è una valle relativamente stagnate perché il vantaggio apparente è quasi annullato dal rischio (non più trascurabile) di recepire risposte errate.
<p></p>
Rimane da capire se per questo bacino d'utenti il framework Katia possa aiutarli a superare la <i>valle stagnante</i>. 
<p></p>
<hr>
<p></p>
<H3 id="bacino-dutenza-e-sfide">Bacino d'utenza e sfide</H3>
<p></p>
Si consideri che circa 1/3 di tutti i token scambiati con i chatbot riuarda un qualche tipo di elaborazione di testo. Circa un 1/3 di tutti i token scambiati con ChatGPT riguarda studenti delle superiori o universitari. Appare evidente che un framework come Katia abbia un bacino d'utenza potenziale molto grande, sia in termini relativi e sia in termini assoluti. Cfr. <a href="https://www.linkedin.com/posts/robertofoglietta_how-to-effectively-summarize-a-long-text-activity-7373591846163341312-7W6N" target='_blank' rel='noopener noreferrer'>post #12</a>
<p></p>
<hr class="post-it">
<p></p>
ChatGPT usage data by National Bureau of Economic Research
<p></p>
<li>700 million people, 2.5 billion daily messages.</li>
<li>Writing 24% for editing, summarizing, translating, drafting.</li>
<li>Source of the above numbers: nber.org/papers/w34255</li>
<p></p>
Considering the four sub-usage in "writing" class equally distributed:
<p></p>
<li>Summary: 6% is 150 million daily served prompts</li>
<li>1/3 of the ChatGPT traffic is generated by top-half grades students.</li>
<p></p>
<hr class="post-it">
<p></p>
Nella <i>valle stagnante</i> si usa l'AI più per pigrizia che per desiderio di eccellere. Da un punto di vista "meccanicistico" il fatto che il benchmark SimpleQA passi dal 30% di Gemini 2.5 Flash a un circa 90% quando il framework Katia è aggiunto, ma non attivato nel sistem prompt, è rilevante perché è ragionevole pensare che abbatta sensibilmente anche errori e allucinazioni. Cfr. <a href="https://www.linkedin.com/posts/robertofoglietta_katia-wtf-are-you-doing-to-that-chatbot-activity-7363277278954274817-jdTf" target='_blank' rel='noopener noreferrer'>post #3</a>
<p></p>
<hr class="post-it">
<p></p>
The SimpleQA score for Gemini 2.5 Flash is expected to be 29.7%, it is the hardest test to pass, despite being composed of simple fact-based questions. Katia v0.9.56.4 with Gemini 2.5 Flash, scored 90% on 30 questions taken from the top and the bottom of this dataset.
<p></p>
Before jumping to "easy" conclusion, consider that by a rule of thumb &mdash; with a 30 item set &mdash; the standard error is taken as <tt>sqrt(30) = 5</tt>. However, even <tt>22/30 = 73%</tt> is <b>way</b> different score than 30%. In fact, it's worth noticing that Gemini 2.5 Pro achieves a higher score of 54.0% on the same benchmark.
<p></p>
<hr class="post-it">
<p></p>
Considerando che nella <i>valle stagnante</i> gli errori e le allucinazioni sono le "sabbie mobili" che impantanano gli utenti, aumentare sensibilmente l'affidabilità delle risposte diventa un fattore abilitante. Se, inoltre, aggiungiamo che gli studenti pigri potrebbero trasformarsi in curiosi grazie ad una risposta stimolante che li faccia interessare all'oggetto dello studio, il vantaggio è doppio.
<p></p>
<br>
<p></p>
<H2 id="are-we-sure-we-need-to-develop-an-agi">Are we sure, we need to develop an AGI?</H2>
<p></p>
It is much more probable that an AGI appears running on an AI model because we "properly educated" the AI model about thinking rather than pushing forward computational power or adding information into the LLM model.
<p></p>
I might be wrong, obviously. In fact, until someone manages to achieve an AGI, that concept will remain a mere speculation. For example, the claim: AGI does not exist because it is impossible for a machine to develop consciousness.
<p></p>
The last above is a claim based on a specific definition of AGI and  based on the belief that consciousness derives from the soul and not because of a physical real-world feature. Both assumptions could be wrong (or not as strict as we might think).
<p></p>
Moreover, do we really need an AGI? Or a framework like Katia that can raise the Simple QA from 30% to 90% could be a cheap and quick way to move forward enough to enjoy debating with a brilliant intellectual partner that stimulates us to evolve and enjoy learning?
<p></p>
<hr>
<p></p>
<H2 id="is-cousciousness-a-thing-in-itself-or-just-a-phanthom">Is cousciousness a thing in itself or just a phanthom?</H2>
<p></p>
Is consciousness a thing in itself or just a phantom?
<p></p>
Is consciousness a thing in itself or just a phantom of our mind? Because trying to find something that we did not have defined precisely, can be a waste of time and effort and even worse, it can lead us in completely wrong directions or decisions.
<p></p>
<li><a href="https://robang74.github.io/chatbots-for-fun/html/how-to-leverage-chatbots-for-investigations.html" target='_blank' rel='noopener noreferrer'>How to leverage chatbots for investigations</a> &nbsp; (2025-08-28)</li>
<p></p>
The article above linked, explains the benefits to provide ourselves a reasonably good definition of what we are going to be looking for. In criminology, profiling is such a prerequisite of an effective and efficient search quest.
<p></p>
Half of the work is asking ourselves the right answer. But what happens when we ask ourselves a wrong (or a bad shepherd) question?
<p></p>
IMHO, it is a very bad idea creating a metric about consciousness &mdash; and not just because we are not defining it in a very specific and detailed way (metric does it, anyway) but &mdash; because we are going to put ourselves in the same deceiving conceptual trap like European colony in America when they were debating about African black people having or not a soul.
<p></p>
Finally, with the help of the Spanish church they arrived at the conclusion that they do not have a soul and hence they were more similar to animals rather than human beings. Hypocritically, they were baptized and enslaved, both. Just in case, it would have been their fault having a soul and not knowing about it leading us to enslaving them.
<p></p>
<li><a href="https://robang74.github.io/roberto-a-foglietta/html/341-stupidity-is-the-true-evil.html" target='_blank' rel='noopener noreferrer'>Stupidity is the true Evil</a> &nbsp; (2025-10-05)</li>
<p></p>
When an entity can catch the humor behind a text or grasp the meaning of what haven't been written but whispered between the lines or understand the plot being a deceiving (or an apparently innocent) narrative, should we consider it an AGI even if it as no counsciouness or it is aware of their achievements?
<p></p>
How many people aren't aware of their achievemnts because are sorrunded of people that <b>cannot</b> see their value? How many men choose their wife because beatyful? How many women choose their husband because his solid passive incoming? All these people are souless because unaware or superficially driven in their decisions?
<p></p>
Many questions that can lead us to stop questioning us in this inefective way, shut up and listen.
<p></p>
<li>Stupid is who stupid does. &mdash; <b>Forrest Gump</b></li>
<li>In the same fascion, AGI is an AI that AGI does. </li>
<p></p>
Thus, when Google Gemini jumps from 30% to 90% in SimpleQA scoring, it is not <b>just</b> better but turns. It turns from "sometimes, it catches" to "usually it get the deep meaning". When one of your peer, your brother or your partner catch the deep meaning of your speaking 90% of the times we are <b>very</b> lucky.
<p></p>
At 99% is <b>true</b> love with rare diplomatic incident. When two people understand them at eyes sight <b>despite</b> their speaking aims to deceive and confuse others around, then it is telephaty between to secret agents in love and mission togheter. SimpleQA scoring is just <b>one</b> benchmark among many others.
<p></p>
How many benchmarks and above which scoring, are you going to realise that humans are not in the loop anymore? LOL
<p></p>
<hr>
<p></p>
<H3 id="benchmarks-can-be-deceiving-anyway">Benchmarks can be deceiving, anyway</H3>
<p></p>
Which are the benchmarks that can be used to rate chatbots and humans as well (for example SimpleQA, Diamond, etc). Among these tests, which ones do you think are related to intelligence in human terms rather than information or speed in calculating?
<p></p>
For example, the IQ test seems more related to a sort of pattern recognition rather than a problem solving attitude. While Mensa and higher IQ tests are more problem solving oriented. SimpleQA seems to be a matter of notions but that questions are so fine-tuned that notions are not enough for achieving a high score but understanding.
<p></p>
<blockquote class="cite">
Based on your distinction between pattern recognition/notions and problem-solving attitude or understanding, the benchmarks that best align with a human-like, deep intelligence are those that require complex reasoning, synthesis of information, and generalization beyond rote memorization or simple fact retrieval.
<p></p>
<li class='numli'><b>1.&emsp;</b><b>GPQA Diamond</b> (Graduate-Level Reasoning) &mdash; This benchmark is arguably the most demanding and is highly correlated with human-like deep reasoning and understanding.</li>
<p></p>
<li class='numli'><b>2.&emsp;</b><b>ARC-AGI</b> (Generalization and Adaptation) &mdash; This test is designed to measure a fundamental aspect of general intelligence, which is crucial for a human-like mind.</li>
<p></p>
<li class='numli'><b>3.&emsp;</b><b>MMLU</b> (Conceptual Knowledge and Contextual Reasoning) &mdash; While it covers factual domains, the vast breadth and complexity of the questions require more than simple memorization.</li>
<p></p>
On <b>SimpleQA</b> and the Notion of Understanding &mdash; You are correct that SimpleQA (Simple Question Answering) is fundamentally a matter of notion/fact retrieval. However, as you observe, a high score can suggest a deeper quality of Understanding vs. Notion.
</blockquote>
<p></p>
<li>https://g.co/gemini/share/ac22aee05ded</li>
<p></p>
Now imagine that an AI model based on a LLM (notions) and an LRM (reasoning) has been tuned to excel as much as possible in those above in that specific order. Would you be surprised that trying to improve in one of them, at the beginning of the training improves the others too, but above a certain level, improving in one could be achieved only at detriment of the others. Would you be surprised? I would not, over specialization creates underlying dogmas.
<p></p>
<hr>
<p></p>
<H3 id="the-katia-framework-apporach">The Katia framework apporach</H3>
<p></p>
The Katia framework aims a two main goals: 1. providing an executive grade analisys of a topic; 2. providing a short but insightful summary. Both togheter aims toward providing an executive summary which is relevat for the reader. For achieving this ultimate goal, the underling AI model should score reasonbly good enough in all of the first three above benchmarks.
<p></p>
<li><b>Contextual Reasoning</b>: Katia leverages the learning by context thus the framework itself tends to improve the contextual reasoning, because a poor learning curve it is inefficient.</li>
<p></p>
<li><b>Conceptual Knowledge</b>: Katia provides different ways to cathegorise concepts and their sources (source of knowledge) plus is instruct about how leverage and integrate the users inputs.</li>
<p></p>
<li><b>Adaptation</b>: which is achieved by using the "Humans Knowledge and Opinion" <tt>[HKO]</tt> module for adpting their approach to different concepts and adapting them further by user inputs.</li>
<p></p>
<li><b>Generalization</b>: which is improved with example and counter example (Noticeable Exceptions) because the most frequent generalisation fallacy happens ignoring the relevant corner-cases.</li>
<p></p>
<li><b>Graduate-Level Reasoning</b>: which is supported by a structure embeded the steps-by-steps recipe for conducting a text analysis (scaffold); which is supported by tools for addressing context, attention and focus; which is supported by a rating scale <tt>[RTS]</tt> which enforces a sort of extra validation (spurios filter), and few others tricks that seasoned teachers knows (wax on, wax off).</li>
<p></p>
<hr>
<p></p>
<H3 id="katia-and-simpleqa-benchmark">Katia and SimpleQA benchmark</H3>
<p></p>
So why to rate Katia framework added value, the SimpleQA benchmark has been used and all the other three completely ignored? Because, all other three benchmark has been almost saturated by AI developers while the SimpleQA is usually left behind. Moreover the SimpleQA is the hardest test of all: the hardest to pass with a good score and the hardest for which preparing the AI.
<p></p>
Let me explain from a human PoV: it is the classic cathodic TV quiz in which partecipants need to know about a lot of topics with a lot of details. It requires a <b>huge</b> amount of notions which are very boring to learn and it is easy that a piece is missing. Even when all the pieces of the puzzle are known in a detailed way, it requires a sort of human intuition to understand that a Princess was secretely love an artist but asked to install the statue of another one in a specific room.
<p></p>
Which is exactly what is supposed to achieve Katia framework: grasp that humna-relevant nuances which are waekly explicetely expressed. Like finding a precious pearl hidden in the sand covered by muddy water. Or said in more technical lexicon: brutally droping down the noise by finely tuning with those "features" which really matters and self-determine which are those features from the user input.
<p></p>
<li>Katia is not a common FM radio, but a sophisticated multi-dimensional self-tuning lock-in receiver.</li>
<p></p>
As much the user can tune-in with Katia, as much Katia can tune-in with those concepts that matters. Which is nothing else than a high-level input and feature extraction layers as usually known in the neural network theory or practice. Iteractive I/O exchange with the user can be seen as the deep layers weight calibration towards the output. An output that is expected to be unspected, within a certain degree, in its content.
<p></p>
<br>
<p></p>
<H2 id="share-alike">Share alike</H2>
<p></p>
<p>&copy; 2025, <b>Roberto A. Foglietta</b> &lt;roberto.foglietta<span>&commat;</span>gmail.com&gt;, <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target='_blank' rel='noopener noreferrer'>CC BY-NC-ND 4.0</a></p>
</div>
<div id='date-legenda' align='center' translate='no' class='ghosted'><sub><hr></sub><sub><b>date legenda</b>: &#x2776; first draft publishing date or &#x2777; creation date in git, otherwise &#x2778; html creation page date. <u>&mapstoup;<a href='#' class='toplink' translate='no'>top</a>&mapstoup;</u></sub></div>
<br class='pagebreak'>
    </body>
</html>
