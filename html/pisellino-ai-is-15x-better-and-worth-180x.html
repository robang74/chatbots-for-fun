<!DOCTYPE html>
<html>
    <head>
        <title>pisellino-ai-is-15x-better-and-worth-180x</title>
        <meta charset='UTF-8'>
        <meta name='viewport' content='width=device-width, initial-scale=1.0'>
        <link rel='shortcut icon' type='image/x-icon' href='favicon.ico?'>
        <link rel='stylesheet' href='default.css'>
        <link rel='stylesheet' href='../intl/intlflg.css'>
        <!-- here begins the Javascript... why for the hell I got here? //-->
        <meta http-equiv='Content-Script-Type' content='text/javascript'>
        <link rel='stylesheet' href='ucustom.css' id='customStylesheet' media='screen'>
        <script>const cssdir='';</script note='global variable'>
        <script src='css-style-changer.js' defer></script>
        <link rel='stylesheet' href='printer.css' media='print'>
    </head>
    <body class=body>
<style>#printlink { display: inline; } @page { size: legal; margin: 0.50in 13.88mm 0.50in 13.88mm; zoom: 100%; } @media print { html { zoom: 100%; } }</style>
<p class='topbar'></p>
<div class='topbar' width='800px' translate='no'><b id='menu' onClick='nextStylesheet()'>&thinsp;&#9783;&thinsp;&Ropf;</b> &thinsp;&mdash;&thinsp; &#8543;&#8239;release: <b class='topbar'>2026-01-12&nbsp;<sup class='date-type topbar' id='datenote'>(&hairsp;<a href='#date-legenda' class='date-type topbar'>2</a>&hairsp;)</sup></b>  &thinsp;&mdash;&thinsp; rev.: <b class='topbar
'>2</b rev_num='
'> &thinsp;&mdash;&thinsp; transl.:&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/pisellino-ai-is-15x-better-and-worth-180x?_x_tr_sl=en&_x_tr_tl=it&_x_tr_hl=it-IT&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>IT</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/pisellino-ai-is-15x-better-and-worth-180x?_x_tr_sl=en&_x_tr_tl=de&_x_tr_hl=de-DE&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>DE</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/pisellino-ai-is-15x-better-and-worth-180x?_x_tr_sl=en&_x_tr_tl=fr&_x_tr_hl=fr-FR&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>FR</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/pisellino-ai-is-15x-better-and-worth-180x?_x_tr_sl=en&_x_tr_tl=es&_x_tr_hl=es-ES&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>ES</a> &thinsp;&mdash;&thinsp; goto:&nbsp; <a class='topbar' href='../index.html#index'>.&#x27F0;.</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='../../roberto-a-foglietta/index.html'target=_blank>RAF</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='../../chatgpt-answered-prompts/index.html'target=_blank>Q&A</a> <span id='printlink'>&thinsp;&mdash;&thinsp; <b>‚éô</b>&hairsp;: <a aria-label='print this page' class='topbar' href='javascript:window.print()'>PDF</a></span>&nbsp;</div>
<div id="firstdiv">
<p class='topbar'></p>
<div align="center"><img class="bwsketch paleinv" src="../img/pisellino-ai-is-15x-better-and-worth-180x.jpg" width="800"><br/></div>
<p></p>
<H2 id="pisellino-ai-is-15x-better-but-it-is-worth-180x-ast">PISELLINO AI IS 15x BETTER BUT IT IS WORTH 180x (&ast;)</H2>
<p></p>
~> lnkd.in/dG4UNt8f (previous post)
<p></p>
Microsoft Bitnet 1.58 2B 4T at 12tk/s on CPU Running T=0.3 ¬± 0.1, Training 2x 5min AICC::1DIR. System prompt 4K tokens 1DIR::JSON, starting time: 1.1s, generates 11.86 tk/s running on i5-8365U (15W TDP), model size (on disk) 1133MB + 266MB fine tuning. Within 12h, I have demonstrated that AICC::1DIRT allows Pisellino AI to run on a ‚Ç¨150 smartphone like Motorola 56G.
<p></p>
An estimation made by Kimi K2 by the numbers I gave to the K2, it is reasoable that in technical value is a 15x: size of the model perceived, quantisation perceived, thus at same utility compared. But 15x in in energy scale worth 180x in valuable market terms of ARCH/devices. Because, it is not just the numbers that matters but the stunning quality of the answer: comparable with an AI model 8B at 8bit of quantisation.
<p></p>
(&ast;) better than the original, value compared the original
<p></p>
Moreover, in this scenario should be considered that Bitnet Q1.56bit 2B params 4T tokens trained, has been chosen because defined by the authors like an accademic proof-of-concept of a tri-state (-1,0,1) quantisation.
<p></p>
<H3 id="first-try-but-a-good-one">FIRST TRY, BUT A GOOD ONE</H3>
<p></p>
~> lnkd.in/dSNUVNMu (github issue)
<p></p>
The toolchain is also not optimised (clang 14 instead of clang 19), the training is not optimised (by only 4K tokens context, it has been retrained for working at 8K tokes), the temperature is not optimised (took the reference for large model T=0.3 ¬± 0.1 while by default it would be T=0.8, instead) and finally, it runs totally on CPU without even try to leverage the basic GPU on the mobile (that makes a sort of boost for the few layers that requires FP8 or FP16 precision). In essence, this is the result of 12h of working and reasonable random choices just to create a PoC based on a PoC.
<p></p>
<H3 id="now-everything-starts-to-make-sense">NOW, EVERYTHING STARTS TO MAKE SENSE</H3>
<p></p>
This series of articles of mine, clearly shows that AI is trapped into a monopoly by NVIDIA because everything other than certified solutions are a hell-to-go, but despite this, a ‚Ç¨250 trashware can provide a stunning ratio between functionality and price/TCO for end-users.
<p></p>
~> lnkd.in/dShrywUd (BoM HP440 + K80)
<p></p>
A great machine to achieve at home the fine-tuning/retraining of SLM. But SLM like Pisellino AI for what? For the edge devices, obviously. Suddenly, it starts to make sense separate the HW firmware (kernel + drivers) from the userland/applications level, which was the aim of RedFish OS:
<p></p>
~> lnkd.in/d8a_pbgp (presentation)
<p></p>
The only way to prevent an AI agent running on the smartphone can tamper with it in a way that even the kernel cannot cope with. Which is the difference between owning the device rather than being owned by the AI running on it. Let me guess, EU politicians made the wrong choice again?
<p></p>
You will be owned (pwned), dig a grave for your hopes. ü§ó üçå
<p></p>
<H2 id="related-articles">Related articles</H2>
<p></p>
<li><a href="orchestrating-ai-intelligence-by-context.html#" target='_blank' rel='noopener noreferrer'>The results from structuring AI's CoT</a> &nbsp; (2025-12-27)</li>
<p></p>
<li><a href="attenzione-e-contesto-nei-chatbot.html#" target='_blank' rel='noopener noreferrer'>Attenzione e contesto nei chatbot</a> &nbsp; (2025-07-20)</li>
<p></p>
<br>
<p></p>
<H2 id="share-alike">Share alike</H2>
<p></p>
<p>&copy; 2025, <b>Roberto A. Foglietta</b> &lt;roberto.foglietta<span>&commat;</span>gmail.com&gt;, <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target='_blank' rel='noopener noreferrer'>CC BY-NC-ND 4.0</a></p>
</div>
<div id='date-legenda' align='center' translate='no' class='ghosted'><sub><hr></sub><sub><b>date legenda</b>: &#x2776; first draft publishing date or &#x2777; creation date in git, otherwise &#x2778; html creation page date. <u>&mapstoup;<a href='#' class='toplink' translate='no'>top</a>&mapstoup;</u></sub></div>
<br class='pagebreak'>
    </body>
</html>
