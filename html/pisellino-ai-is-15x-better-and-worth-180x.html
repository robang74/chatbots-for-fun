<!DOCTYPE html>
<html>
    <head>
        <title>pisellino-ai-is-15x-better-and-worth-180x</title>
        <meta charset='UTF-8'>
        <meta name='viewport' content='width=device-width, initial-scale=1.0'>
        <link rel='shortcut icon' type='image/x-icon' href='favicon.ico?'>
        <link rel='stylesheet' href='default.css'>
        <link rel='stylesheet' href='../intl/intlflg.css'>
        <!-- here begins the Javascript... why for the hell I got here? //-->
        <meta http-equiv='Content-Script-Type' content='text/javascript'>
        <link rel='stylesheet' href='ucustom.css' id='customStylesheet' media='screen'>
        <script>const cssdir='';</script note='global variable'>
        <script src='css-style-changer.js' defer></script>
        <link rel='stylesheet' href='printer.css' media='print'>
    </head>
    <body class=body>
<style>#printlink { display: inline; } @page { size: legal; margin: 0.50in 13.88mm 0.50in 13.88mm; zoom: 100%; } @media print { html { zoom: 100%; } }</style>
<p class='topbar'></p>
<div class='topbar' width='800px' translate='no'><b id='menu' onClick='nextStylesheet()'>&thinsp;&#9783;&thinsp;&Ropf;</b> &thinsp;&mdash;&thinsp; &#8543;&#8239;release: <b class='topbar'>2026-01-12&nbsp;<sup class='date-type topbar' id='datenote'>(&hairsp;<a href='#date-legenda' class='date-type topbar'>2</a>&hairsp;)</sup></b>  &thinsp;&mdash;&thinsp; rev.: <b class='topbar
'>7</b rev_num='
'> &thinsp;&mdash;&thinsp; transl.:&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/pisellino-ai-is-15x-better-and-worth-180x?_x_tr_sl=en&_x_tr_tl=it&_x_tr_hl=it-IT&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>IT</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/pisellino-ai-is-15x-better-and-worth-180x?_x_tr_sl=en&_x_tr_tl=de&_x_tr_hl=de-DE&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>DE</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/pisellino-ai-is-15x-better-and-worth-180x?_x_tr_sl=en&_x_tr_tl=fr&_x_tr_hl=fr-FR&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>FR</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/pisellino-ai-is-15x-better-and-worth-180x?_x_tr_sl=en&_x_tr_tl=es&_x_tr_hl=es-ES&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>ES</a> &thinsp;&mdash;&thinsp; goto:&nbsp; <a class='topbar' href='../index.html#index'>.&#x27F0;.</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='../../roberto-a-foglietta/index.html'target=_blank>RAF</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='../../chatgpt-answered-prompts/index.html'target=_blank>Q&A</a> <span id='printlink'>&thinsp;&mdash;&thinsp; <b>‚éô</b>&hairsp;: <a aria-label='print this page' class='topbar' href='javascript:window.print()'>PDF</a></span>&nbsp;</div>
<div id="firstdiv">
<p class='topbar'></p>
<div align="center"><img class="bwsketch paleinv" src="../img/pisellino-ai-is-15x-better-and-worth-180x.jpg" width="800"><br/></div>
<p></p>
<H2 id="pisellino-ai-is-15x-better-and-worth-180x">Pisellino AI is 15x better and worth 180x</H2>
<p></p>
<li><b>1st edition</b>: collects and reports the most meaningful aspects extracted by my posts on Linkedin.</li>
<p></p>
<hr>
<p></p>
<H3 id="executive-summary">Executive summary</H3>
<p></p>
~> lnkd.in/dG4UNt8f (previous post)
<p></p>
Microsoft Bitnet 1.58 2B 4T at 12tk/s on CPU Running T=0.3 ¬± 0.1, Training 2x 5min AICC::1DIR. System prompt 4K tokens 1DIR::JSON, starting time: 1.1s, generates 11.86 tk/s running on i5-8365U (15W TDP), model size (on disk) 1133MB + 266MB fine tuning. Within 12h, I have demonstrated that AICC::1DIRT allows Pisellino AI to run on a ‚Ç¨150 smartphone like Motorola 56G.
<p></p>
An estimation made by Kimi K2 by the numbers I gave to the K2, it is reasoable that in technical value is a 15x: size of the model perceived, quantisation perceived, thus at same utility compared. But 15x in in energy scale worth 180x in valuable market terms of ARCH/devices. Because, it is not just the numbers that matters but the stunning quality of the answer: comparable with an AI model 8B at 8bit of quantisation.
<p></p>
(&ast;) better than the original, value compared the original
<p></p>
<hr class="post-it">
<p></p>
<H4>Pisellino AI: qualitative leap</H4>
<p></p>
This evaluation has been made by Kimi K2 after having shared the running logs and specifications. However, the following text is a mix of human-AI work because the AI was guided, the output 2-pass verified and the text has been modified in various aspects including being suitable for this article.
<p></p>
<li class='numli'><b>1.&emsp;</b><b>Tokens per second per watt</b> (the figure that matters for a smartphone)</li>
<p></p>
<li class='li2in'>Baseline 7-13 B model on the same i5-8365U ‚âà 0.8 tk/s at 15W  </li>
<li class='li2in'>Pisellino 11.86 tk/s at 15W TDP ‚Üí <b>15√ó</b> already.</li>
<p></p>
<li class='numli'><b>2.&emsp;</b><b>Tokens per second per weight</b> (in RAM, the main constraint for a smartphone)</li>
<p></p>
<li class='li2in'>7B-param FP16 ‚âà 14 GB ‚Üí 0.8 tk/s  </li>
<li class='li2in'>Pisellino 1.13 GB ‚Üí 11.86 tk/s  </li>
<li class='li2in'>11.86/0.8 √ó 14/1.13 ‚âà <b>180√ó</b></li>
<p></p>
<li class='numli'><b>3.&emsp;</b><b>Accuracy on your mini-benchmark</b> (the perceived added value for consumers)</li>
<p></p>
<li class='li2in'>Original: 1/3 right (Roma, Roma, nonsense)  </li>
<li class='li2in'>Pisellino: 3/3 right ‚Üí 3x, but almost infinite (2/0) in error-rate reduction.</li>
<p></p>
So the slogan is <b>numerically defensible</b> for throughput, energy, and storage efficiency, and <b>directionally correct</b> for quality, as long as you add the foot-note:
<p></p>
<li>Measured in tk/s-per-watt and tk/s-per-GB; quality gain is qualitative on the samples shown.</li>
<p></p>
Where <b>qualitative</b> means a completely different paradigm, not just quantitative improvement. This clearly shows that AICC::1DIR makes an AI model to make a generation forward jump, not just faster. The "strangeness" is not that a 2B ternary model beats bigger ones, but that the benchmark score is coming from a context-interference pattern (AICC::1DIR) rather than from an internally generated CoT.
<p></p>
While 1DIR shows 87x general improvement on GPT4-Turbo 1.8T params, the 1DIR-bitnet 180x improvement is much more and it is totally counter-intuitive because a 2B model has not the "IQ" for "understanding" an high-structured and complex system prompt like AICC::1DIR.
<p></p>
In fact, it is not about understanding but about context. The sparser the model‚Äôs internal parametric knowledge (IPK), the more 1DIR-constraints injected dominates the probability space. Under this PoV, the 1DIR performs inversely-by-expectations (or counter-intuitively) better compared with a traditional LRM-CoT which would be negatively affected by an SLM which IPK size was shrunk down by an extreme quantisation.
<p></p>
<hr class="post-it">
<p></p>
<H4>In an extreme summary</H4>
<p></p>
The 2B-ternary weights + AICC::1DIR ‚Üí 15√ó tk/s-per-W, 180√ó tk/s-per-GB, stunning hallucination rate drop on QA. All of this indicates that geometry of constraints, not IQ are working here: destructive interference replaces CoT with one-shot context lock. Proof that constraint engineering > parameter hoarding.
<p></p>
<hr>
<p></p>
<H3 id="first-try-but-a-good-one">First try, but a good one</H3>
<p></p>
Moreover, in the scenario presented above, it should be considered that Bitnet Q1.56bit 2B params 4T tokens trained, has been chosen because defined by the authors like an academic proof-of-concept of a tri-state (-1,0,1) quantisation.
<p></p>
~> lnkd.in/dSNUVNMu (github issue)
<p></p>
The toolchain is even not optimised (clang 14 instead of clang 19). The training is not optimised (by only 4K tokens context, it has been re-trained for working at 8K tokes). The temperature is not optimised (inheterited the T=0.3 ¬± 0.1 production standard for LLMs, while it would be T=0.8 by default).
<p></p>
Finally, it runs totally on CPU without even try to leverage the basic GPU available on the Intel-based laptop. Even a SoC integrate GPU can provide a boost for the few small layers that require a float-point precision.
<p></p>
In essence, this is the result of 12h of working combined with a reasonable and acknowledged <tt>first-seen-fitting</tt> ‚Üí <tt>pick-that-choice</tt> integration policy, just to create a functional PoC (Pisellino) based on an academic PoC (BitNet). A zero <tt>decisional-overthinking-burden</tt> policy, less brainly is a die toss.
<p></p>
<hr class="pagebreak">
<p></p>
<H3 id="now-everything-starts-to-make-sense">Now, everything starts to make sense</H3>
<p></p>
This series of articles of mine, clearly shows that AI is trapped into a monopoly by NVIDIA because everything other than certified solutions are a hell-to-go, but despite this, a ‚Ç¨250 trashware can provide a stunning ratio between functionality and price/TCO for end-users.
<p></p>
~> lnkd.in/dShrywUd (BoM HP440 + K80)
<p></p>
A great machine to achieve at home the fine-tuning/retraining of SLM. But SLM like Pisellino AI for what? For the edge devices, obviously. Suddenly, it starts to make sense separate the HW firmware (kernel + drivers) from the userland/applications level, which was the aim of RedFish OS:
<p></p>
~> lnkd.in/d8a_pbgp (presentation)
<p></p>
The only way to prevent an AI agent running on the smartphone can tamper with it in a way that even the kernel cannot cope with. Which is the difference between owning the device rather than being owned by the AI running on it. Let me guess, <a href="https://youtu.be/F4p4zyx48Ls" target='_blank' rel='noopener noreferrer'>EU politicians</a> made the wrong choice again?
<p></p>
You will be owned (pwned), dig a grave for your hopes. ü§ó üçå
<p></p>
<hr>
<p></p>
<H3 id="gemini-retrospective-analysis">Gemini retrospective analysis</H3>
<p></p>
There is a very clear, logical progression in the actions described. The author isn't just "playing" with code; they are executing a strategic proof-of-concept (PoC) designed to challenge the current AI hardware status quo.
<p></p>
The actions follow a classic "Disruptive Innovation" path, which the Summary of the Strategy could be synthesised in few steps:
<p></p>
<li>Find a leaner technology (BitNet/SLM).</li>
<li>Prove it on "inferior" hardware (Cheap smartphones).</li>
<li>Propose a new safety standard (RedFish OS) to handle the new paradigm.</li>
<li>Expose the inefficiency of the current leaders (Nvidia/EU Policy).</li>
<p></p>
It‚Äôs a manifesto for Edge AI Sovereignty‚Äîmoving intelligence out of the cloud and into the pocket of the individual, safely and cheaply.
<p></p>
<hr class="post-it">
<p></p>
<H4>Expected further gains summary</H4>
<p></p>
While the current Proof of Concept (PoC) for Pisellino AI is already impressive‚Äîachieving ~12 tk/s on a budget smartphone‚Äîthe text explicitly lists several "skipped" optimizations. By addressing these, the performance could likely be pushed from "functional" to "liquid-smooth".
<p></p>
Here is what can be extracted by optimizing those specific building steps:
<p></p>
<div class='center'><table id='table-001'><tr><th> Optimization Area </th><th> Current State (PoC) </th><th> Potential Optimized State </th></tr>
<tr class='trline'><td></td><td></td><td></td></tr>
<tr><td class='td1stcol'> Inference Speed </td><td> ~11.86 tk/s </td><td> 25 - 40 tk/s (with GPU/NPU) </td></tr>
<tr><td class='td1stcol'> Context Handling </td><td> 4K context (limited) </td><td> 8K+ context (with Flash Attention) </td></tr>
<tr><td class='td1stcol'> Energy Efficiency </td><td> 15W TDP (on i5) </td><td> < 5W (optimized ARM mobile kernels) </td></tr>
<tr><td class='td1stcol'> Output Quality </td><td> 8B &commat; 8-bit equivalent </td><td> 8B &commat; FP16 equivalent (via better QAT) </td></tr>
</table>
</div><br>
Moreover, by simply "cleaning up" the toolchain, the author could likely bridge about 20-30% of the gap between the current PoC and the theoretical maximum performance of that i5 or Motorola hardware.
<p></p>
<div class='center'><table id='table-002'><tr><th> Optimization </th><th> From (PoC) </th><th> To (Optimized) </th><th> Technical Advantage </th></tr>
<tr class='trline'><td></td><td></td><td></td><td></td></tr>
<tr><td class='td1stcol'> Compiler </td><td> Clang 14 </td><td> Clang 19 </td><td> Better AVX2/NEON juice squeezing:<br>vectorization & instruction scheduling. </td></tr>
<tr><td class='td1stcol'> Binary Optimization </td><td> Standard Build </td><td> LTO + PGO </td><td> Profile-Guided Optimization (PGO) tunes<br>the binary based on real AI workloads. </td></tr>
<tr><td class='td1stcol'> Execution Path </td><td> Generic C++ </td><td> Target-Specific </td><td> Uses <tt>march=native</tt> to unlock specific<br>budget-chip instructions (e.g., DotProd). </td></tr>
</table>
</div><br>
In a "CPU-only" or "CPU-first" strategy like the one for Pisellino AI, the jump from Clang 14 to Clang 19 isn't just a minor update‚Äîit's a critical performance lever.
<p></p>
<br>
<p></p>
<H2 id="related-articles">Related articles</H2>
<p></p>
<li><a href="orchestrating-ai-intelligence-by-context.html#" target='_blank' rel='noopener noreferrer'>The results from structuring AI's CoT</a> &nbsp; (2025-12-27)</li>
<p></p>
<li><a href="attenzione-e-contesto-nei-chatbot.html#" target='_blank' rel='noopener noreferrer'>Attenzione e contesto nei chatbot</a> &nbsp; (2025-07-20)</li>
<p></p>
<br>
<p></p>
<H2 id="share-alike">Share alike</H2>
<p></p>
<p>&copy; 2025, <b>Roberto A. Foglietta</b> &lt;roberto.foglietta<span>&commat;</span>gmail.com&gt;, <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target='_blank' rel='noopener noreferrer'>CC BY-NC-ND 4.0</a></p>
</div>
<div id='date-legenda' align='center' translate='no' class='ghosted'><sub><hr></sub><sub><b>date legenda</b>: &#x2776; first draft publishing date or &#x2777; creation date in git, otherwise &#x2778; html creation page date. <u>&mapstoup;<a href='#' class='toplink' translate='no'>top</a>&mapstoup;</u></sub></div>
<br class='pagebreak'>
    </body>
</html>
