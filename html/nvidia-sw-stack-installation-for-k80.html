<!DOCTYPE html>
<html>
    <head>
        <title>nvidia-sw-stack-installation-for-k80</title>
        <meta charset='UTF-8'>
        <meta name='viewport' content='width=device-width, initial-scale=1.0'>
        <link rel='shortcut icon' type='image/x-icon' href='favicon.ico?'>
        <link rel='stylesheet' href='default.css'>
        <link rel='stylesheet' href='../intl/intlflg.css'>
        <!-- here begins the Javascript... why for the hell I got here? //-->
        <meta http-equiv='Content-Script-Type' content='text/javascript'>
        <link rel='stylesheet' href='ucustom.css' id='customStylesheet' media='screen'>
        <script>const cssdir='';</script note='global variable'>
        <script src='css-style-changer.js' defer></script>
        <link rel='stylesheet' href='printer.css' media='print'>
    </head>
    <body>
<style>#printlink { display: inline; } @page { size: legal; margin: 0.50in 13.88mm 0.50in 13.88mm; zoom: 100%; } @media print { html { zoom: 100%; } }</style>
<p class='topbar'></p>
<div class='topbar' width='800px' translate='no'><b id='menu' onClick='nextStylesheet()'>&thinsp;&#9783;&thinsp;&Ropf;</b> &thinsp;&mdash;&thinsp; &#8543;&#8239;release: <b class='topbar'>2025-02-18&nbsp;<sup class='date-type topbar' id='datenote'>(&hairsp;<a href='#date-legenda' class='date-type topbar'>1</a>&hairsp;)</sup></b>  &thinsp;&mdash;&thinsp; rev.: <b class='topbar
'>15</b rev_num='
'> &thinsp;&mdash;&thinsp; transl.:&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/nvidia-sw-stack-installation-for-k80?_x_tr_sl=en&_x_tr_tl=it&_x_tr_hl=it-IT&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>IT</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/nvidia-sw-stack-installation-for-k80?_x_tr_sl=en&_x_tr_tl=de&_x_tr_hl=de-DE&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>DE</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/nvidia-sw-stack-installation-for-k80?_x_tr_sl=en&_x_tr_tl=fr&_x_tr_hl=fr-FR&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>FR</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='https://robang74-github-io.translate.goog/chatbots-for-fun/html/nvidia-sw-stack-installation-for-k80?_x_tr_sl=en&_x_tr_tl=es&_x_tr_hl=es-ES&_x_tr_pto=wapp' target='_blank' rel='noopener noreferrer'>ES</a> &thinsp;&mdash;&thinsp; goto:&nbsp; <a class='topbar' href='../index.html#index'>.&#x27F0;.</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='../../roberto-a-foglietta/index.html'target=_blank>RAF</a> &nbsp;<b>&middot;</b>&nbsp; <a class='topbar' href='../../chatgpt-answered-prompts/index.html'target=_blank>Q&A</a> <span id='printlink'>&thinsp;&mdash;&thinsp; <b>⎙</b>&hairsp;: <a aria-label='print this page' class='topbar' href='javascript:window.print()'>PDF</a></span>&nbsp;</div>
<div id="firstdiv">
<p class='topbar'></p>
<div align="center"><img class="bwsketch" src="../img/nvidia-tesla-k80.png" width="800"><br></div>
<p></p>
<H2 id="nvidia-tesla-k80-installation">Nvidia Tesla K80 installation</H2>
<p></p>
<li>This paper is part of the <a href="p910-k80-installation-manual-intro.html#" target='_blank' rel='noopener noreferrer'>Fujitsu P910 w/ Tesla K80 installation manual</a> serie.</li>
<p></p>
Let me introduce the Nvidia Tesla K80 accelerator board, which is not a graphic card for the consumer market but an accelerator for data centers.
<p></p>
<li>4992 NVIDIA CUDA cores with dual GPU design each with 12Gb of RAM</li>
<li>Up to 2.91 teraflops of double precision performance with NVIDIA GPU Boost</li>
<li>Up to 8.73 teraflops of single precision performance with NVIDIA GPU Boost</li>
<li>24GB GDDR5 memory with 480GB/s aggregate memory bandwidth</li>
<li>Server optimised with ECC protection for maximum reliability</li>
<li>1 PCI express 3.0 16x bus, 2 slots large, 225W TDP 300W max.</li>
<li>Kepler architecture, market entry 17 November 2014 at $7.000</li>
<p></p>
It is a 10yo hardware which has NOT been designed for being put into a desktop computer, so it does not have an active cooling system by itself. Currently, its support is DEPRECATED and it will not be ported further to the 470 series of drivers and CUDA software stack, officially. Which is one of the reasons because it can be bought for something between $100 and $200 on the refurbished market. The other main reason for its relatively cheap price is a sort of gambling/bricolage activity to make it work with desktop hardware. So, here we are! <img class='emoji wbsketch' src='../img/emoji/smile.png'>
<p></p>
<hr>
<p></p>
<H3 id="alternatives-gpu-cards">Alternatives GPU cards</H3>
<p></p>
First of all, we need to establish the main reason for adopting a Tesla K80: locally running AI models mainly and occasionally their training, fine-tuning, and similar activities. This is essential to prioritise the memory size in GB versus the computational power expressed in CUDA cores.
<p></p>
For a comparison, to have the same CUDA cores and RAM, it is necessary to have 2x GeForce RTX 2060 12GB which requires 2x PCI-express 3.0 16x slots but occupies 4 slots and consumes 184W max. each, for a 312W TDP and 370W max. While using 2x GeForce RTX 3060 12 GB requires the newer PCI express 4.0 bus, sharply increasing the cost of the supporting hardware. Another option is combining 2x GeForce GTX 1080 8GB. All these options are facing the challenge to allocate 2 PCI-express 3.0 16x slots using 4 slots space. All these options go from €400 and €800 on Amazon and their prices are not much lower on the used market.
<p></p>
Therefore a competitive alternative to the Tesla K80/K40 is the Quadro M6000 with 24GB or 12GB. The sensitive advantages are 24GB available on a single GPU with 3072 CUDA cores, a video card designed for PC desktop installation and 250W max. consumption. Likely the Tesla K80/K40 the support is limited to the version 470 (LTS) but its price on the refurbished market is much higher and on the private used market it stays above €400, usually. The reason is clear, it is a PC desktop graphic card highly performant. While an accelerator card for scientific purposes designed for the server market is not so much appreciated.
<p></p>
<blockquote><span class="warnicon spanicon">&nbsp;<svg class="warnicon svgicon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path></svg><nobr class="alerts" translate="no">&nbsp;&nbsp;WARNING!&nbsp;&nbsp;</nobr></span><br><br>Prices might vary and in particular on the refurbished and used markets can be greatly volatile. The prices provided here should be considered as a rule-of-thumb reference within the limitation of a snapshot taken in early 2025.</blockquote>
<p></p>
<blockquote><span class="infoicon spanicon">&nbsp;<svg class="infoicon svgicon" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path></svg><nobr class="alerts" translate="no">&nbsp;&nbsp;&middot;NOTICE&middot;&nbsp;&nbsp;</nobr></span><br><br>Price ranges have been presented here to provide to the readers the information that they have to expect to spend x2 at least on the used market for a M6000 solution compared with one based on K80/K40 cards. Up to 4x when a new dual card PCIe 3.0 gets into the picture and up to 8x for a new PCIe 4.0 solution. This means that from €200-€250 of a K80 cheap home-assembled solution, the price can sharply increase up to €2.000 when more comfortable (no gambling, no bricolage) and gaming oriented solutions are considered.</blockquote>
<p></p>
<hr>
<p></p>
<H3 id="ubuntu-as-operative-system">Ubuntu as operative system</H3>
<p></p>
Ubuntu Linux is a well-known widely-spread GNU/Linux distribution which has the vastest hardware support and an user-friendly eye-candy looking graphical user interface. Despite all its whistle and bells, it still pretty usable with old hardware even 10yo architectures and on top of this, it is a solid, full-fledged UNIX/Posix operating system with all the benefits of an Open-Source Software Libre solution included a relatively large user-base and commercial support for enterprises including server, data-center and cloud applications, also.
<p></p>
<H4>Checking the boot</H4>
<p></p>
After having installed the Tesla K80, provided to it the necessary power with a dual-PSU cheap solution and a reasonable cooling system at least for the early testing, it is the right time for checking the <tt>dmesg -l err,warn,crit</tt> output in search of troubles. Troubles, the kind of flowers that bloom in every season! <img class='emoji wbsketch' src='../img/emoji/wink.png'>
<p></p>
<blockquote class="code"><code>
pnp 00:05: disabling [mem 0xfed1c000-0xfed1ffff disabled] because it overlaps<br>
\_0000:04:00.0 BAR 1 [mem 0x00000000-0x3ffffffff 64bit pref]<br>
 ...<br>
pnp 00:05: disabling [mem 0xdfa00000-0xdfa00fff disabled] because it overlaps<br>
\_0000:04:00.0 BAR 1 [mem 0x00000000-0x3ffffffff 64bit pref]<br>
pnp 00:06: disabling [mem 0x20000000-0x201fffff] because it overlaps<br> 
\_0000:03:00.0 BAR 1 [mem 0x00000000-0x3ffffffff 64bit pref]<br>
 ...<br>
pnp 00:06: disabling [mem 0x20000000-0x201fffff disabled] because it overlaps<br>
\_0000:04:00.0 BAR 1 [mem 0x00000000-0x3ffffffff 64bit pref]<br>
 ...<br>
</code></blockquote>
<p></p>
In fact, these strings do not promise anything good or easy to cope with. However, similar strings are present also on my Thinkpad x390 and everything is working fine. Unfortunately, <tt>lspci -vt</tt> confirms that <tt>03:00.0</tt> and <tt>04:00.0</tt> are related to the Tesla K80. Fortunately, the <tt>dmesg -l err,crit</tt> output is void which means that they are warnings.
<p></p>
<div class="pagebreak"><hr></div>
<p></p>
<H4>Disabling nouveau</H4>
<p></p>
The next step to take is adding <tt>nouveau.modeset=0</tt> to the kernel command line because nouveau is the generic open-source driver for Nvidia graphic cards, we do not want it because we need to rely on the Nvidia driver to leverage the CUDA software stack plus the Tesla K80 is headless, it has no video monitor support, which means <tt>modeset=0</tt> anyway. For the same reason we do not need also nvidia_drm and nvidia_modeset modules because they are related to graphic functioning while in our case is compute-only installation.
<p></p>
<li class='numli'><b>1.&emsp;</b>open for editing <tt>/etc/default/grub</tt> which requires <tt>sudo</tt> root permission</li>
<li class='numli'><b>2.&emsp;</b>add the <tt>nouveau.modeset=0</tt> parameter into <tt>GRUB_CMDLINE_LINUX_DEFAULT</tt></li>
<li class='numli'><b>3.&emsp;</b>save the file, <tt>update-grub</tt> to write the change in boot sector</li>
<li class='numli'><b>4.&emsp;</b>reboot the system and check the change with <tt>grep modeset /proc/cmdline</tt></li>
<p></p>
With this change in place, we are ready to engage the Nvidia driver and CUDA software stack installation.
<p></p>
<H4>CUDA support</H4>
<p></p>
The command <tt>nvcc --version</tt> will display the version of CUDA installed. The Tesla K80 has CUDA compute capability 3.7 which is deprecated but still supported, while Kepler architecture was supported until CUDA version 11.8.
<p></p>
<blockquote>While some elements might function, relying on CUDA 11.8 for full Kepler support is incorrect. It's safer to say CUDA 11.4 is the practical and fully supported limit. Based on Nvidia documentation, for that driver series, the 11.4 is the most stable and reliable version to use. &mdash; Gemini 2</blockquote>
<p></p>
Ubuntu 22.04 and 24.04 LTS are offering CUDA 11.5 with the 470 driver series which reasonably suggests that the system can work but is not certifiable under Nvidia's recommendations. Therefore, the K80 is the most powerful among old deprecated but still supported GPU cards by upstream sources.
<p></p>
<hr>
<p></p>
<H3 id="ubuntu-nvidia-sw-installation">Ubuntu Nvidia SW installation</H3>
<p></p>
First of all, some basic information about installing Nvidia SW stack and drivers which releases comes in two packages types:
<p></p>
<li>UDA (Unified Driver Architecture) drivers which are recommended for the generic desktop use, and it is available here: <a href="https://www.nvidia.com/en-us/drivers/unix/" target='_blank' rel='noopener noreferrer'>nvidia.com about unix drivers</a></li>
<p></p>
<li>ERD (Enterprise Ready Drivers) which are recommended on servers, and for computing tasks. Their packages can be recognised by the <tt>-server</tt> suffix. More information about</li>
these drivers are available here: <a href="https://docs.nvidia.com/datacenter/tesla/index.html" target='_blank' rel='noopener noreferrer'>docs.nvidia.com about tesla</a>
<p></p>
The recommended way to install on Ubuntu is to leverage its tools:
<p></p>
<li>The ubuntu-drivers tool relies on the same logic as the "Additional Drivers" graphical tool, and allows more flexibility on desktops and on servers.</li>
<p></p>
<li>The ubuntu-drivers tool is recommended if Secure Boot is in use, since it always tries to install signed drivers which are known to work with it.</li>
<p></p>
Check the available drivers for the hardware with <tt>sudo ubuntu-drivers list</tt> and use the <tt>--gpgpu</tt> for the server version. To install the drivers: <tt>sudo ubuntu-drivers install</tt> which allows us to specify the version <tt>nvidia:470</tt> and the <tt>--gpgpu</tt> server edition. To check the version of the currently running driver: <tt>cat /proc/driver/nvidia/version</tt>.
<p></p>
Following the most straightforward installation procedure, plus adding some useful tools:
<p></p>
<blockquote class="code"><code>
root&commat;p910:~# update-pciids<br>
<p></p>
root&commat;p910:~# ubuntu-drivers list<br>
nvidia-driver-470-server, (linux-modules-nvidia-470-server-generic-hwe-24.04)<br>
nvidia-driver-470, (linux-modules-nvidia-470-generic-hwe-24.04)<br>
<p></p>
root&commat;p910:~# ubuntu-drivers install<br>
 ...<br>
done<br>
<p></p>
root&commat;p910:~# add-apt-repository ppa:danielrichter2007/grub-customizer -y<br>
root&commat;p910:~# apt-get install grub-customizer modprobe-nvidia nvtop -y<br>
</code></blockquote>
<p></p>
and before rebooting the system, adding a kernel command line parameters <tt>modprobe.blacklist=nouveau</tt> in <tt>/etc/default/grub</tt> file to prevent nvidia generic driver mess up things, then update the initramfs and the grub boot record, as shown here below:
<p></p>
<blockquote class="code"><code>
echo "blacklist nouveau" >> /etc/modprobe.d/blacklist.conf
<p></p>
root&commat;p910:~# update-initramfs -u<br>
update-initramfs: Generating /boot/initrd.img-6.11.0-17-generic<br>
<p></p>
root&commat;p910:~# update-grub<br>
 ...<br>
done<br>
</code></blockquote>
<p></p>
After the reboot:
<p></p>
<blockquote class="code"><code>
root&commat;p910:~# cat /proc/driver/nvidia/version<br>
NVRM version: NVIDIA UNIX x86_64 Kernel Module 470.256.02 Thu May  2 14:37:44 UTC 2024<br>
<p></p>
root&commat;p910:~# nvidia-smi<br>
No devices were found<br>
<p></p>
root&commat;p910:~# dmesg -l err,crit<br>
<p></p>
root&commat;p910:~# dmesg -l err,warn,crit  | grep NV | cut -d] -f2-<br>
 nvidia: module license 'NVIDIA' taints kernel.<br>
 NVRM: loading NVIDIA UNIX x86_64 Kernel Module  470.256.02 Thu May  2 14:37:44 UTC 2024<br>
 NVRM: GPU 0000:03:00.0: RmInitAdapter failed! (0x22:0xffff:667)<br>
 NVRM: GPU 0000:03:00.0: rm_init_adapter failed, device minor number 0<br>
 ...<br>
 NVRM: GPU 0000:04:00.0: RmInitAdapter failed! (0x22:0xffff:667)<br>
 NVRM: GPU 0000:04:00.0: rm_init_adapter failed, device minor number 1<br>
</code></blockquote>
<p></p>
Trying with a manual installation does not help:
<p></p>
<blockquote class="code"><code>
root&commat;p910:~# apt list --installed | grep nvidia | cut -d, -f1<br>
libnvidia-cfg1-470/noble-updates<br>
libnvidia-common-470/noble-updates<br>
libnvidia-compute-470/noble-updates<br>
libnvidia-extra-470/noble-updates<br>
linux-modules-nvidia-470-6.11.0-17-generic/noble-updates<br>
linux-modules-nvidia-470-generic-hwe-24.04/noble-updates<br>
linux-objects-nvidia-470-6.11.0-17-generic/noble-updates<br>
linux-signatures-nvidia-6.11.0-17-generic/noble-updates<br>
nvidia-compute-utils-470/noble-updates<br>
nvidia-kernel-common-470/noble-updates<br>
nvidia-utils-470/noble-updates<br>
</code></blockquote>
<p></p>
Which is not good at all, but the following is even worse:
<p></p>
<blockquote class="code"><code>
root&commat;p910:~# cat /proc/driver/nvidia/gpus/*/information<br>
Model: Tesla K80<br>
IRQ:    39<br>
GPU UUID: GPU-????????-????-????-????-????????????<br>
Video BIOS: ??.??.??.??.??<br>
Bus Type: PCIe<br>
DMA Size: 36 bits<br>
DMA Mask: 0xfffffffff<br>
Bus Location: 0000:03:00.0<br>
Device Minor: 0<br>
GPU Excluded: No<br>
Model: Tesla K80<br>
IRQ:    39<br>
GPU UUID: GPU-????????-????-????-????-????????????<br>
Video BIOS: ??.??.??.??.??<br>
Bus Type: PCIe<br>
DMA Size: 36 bits<br>
DMA Mask: 0xfffffffff<br>
Bus Location: 0000:04:00.0<br>
Device Minor: 1<br>
GPU Excluded: No<br>
</code></blockquote>
<p></p>
<hr>
<p></p>
<span id="is-eol-green"></span>
<H3 id="p910-e85-pcie-support-4gb-only">P910 E85+ PCIe support 4GB only</H3>
<p></p>
This is <b>VERY BAD</b> because indicates a hardware incompatibility with the motherboard or its BIOS. Considering that the Esprimo P910 has its own Fujitsu ATX power unit with a custom 16-pin connector, changing the motherboard is furtherly complicated by the challenge to find one within the P910 family by Fujitsu. Otherwise, it is easier to change the whole P910 for something else, completely.
<p></p>
<blockquote class="code"><code>
root&commat;p910:~# mokutil --sb-state<br>
SecureBoot disabled<br>
<p></p>
root&commat;p910:~# lsmod | grep -e video -e nvidia<br>
nvidia_uvm           1437696  0<br>
nvidia_drm             77824  2<br>
nvidia_modeset       1212416  1 nvidia_drm<br>
nvidia              35643392  2 nvidia_uvm,nvidia_modeset<br>
video                  73728  2 i915,nvidia_modeset<br>
wmi                    28672  1 video<br>
<p></p>
root&commat;p910:~# systemctl status nvidia-persistenced | grep active<br>
 &nbsp; Active: active (running) since Thu 2025-02-20 05:10:08 CET; 10min ago<br>
<p></p>
root&commat;p910:~# lspci -vvv |grep -iA 20 nvidia|grep -ie region -ie lnkcap:<br>
 &nbsp; Region 0: Memory at f0000000 (32-bit, non-prefetchable) [size=16M]<br>
 &nbsp; &nbsp; LnkCap: Port #8, Speed 8GT/s, Width x16, ASPM not supported<br>
 &nbsp; Region 0: Memory at f1000000 (32-bit, non-prefetchable) [size=16M]<br>
 &nbsp; &nbsp; LnkCap: Port #16, Speed 8GT/s, Width x16, ASPM not supported<br>
</code></blockquote>
<p></p>
Which is <b>WAY</b> different than the expected output, which should be something like this:
<p></p>
<blockquote class="code"><code>
 &nbsp; Region 0: Memory at f8000000 (32-bit, non-prefetchable)<br>
 &nbsp; Region 1: Memory at d8000000 (64-bit, prefetchable)<br>
 &nbsp; Region 3: Memory at d4000000 (64-bit, prefetchable)<br>
</code></blockquote>
<p></p>
In fact, the problem is that BAR1 and BAR2, both 64-bit prefetchable, are missing for both devices which means that the PCIe is 4GB addressable but not beyond that limit.
<p></p>
<div class="pagebreak"><hr></div>
<p></p>
<span id="bios-as-fw"></span>
<H3 id="why-pc-still-have-a-bios">Why PC still have a BIOS?</H3>
<p></p>
The BIOS (Basic Input Output System) is a firmware stored in a separate chip, but why does a modern Personal Computer still have a troubles-maker firmware for booting?
<p></p>
Even an ARM system requires some kind of hardware initialisation at boot time, but why put such a thing into a separate chip instead of into UEFI (Unified Extensible Firmware Interface)?
<p></p>
<blockquote>The 80286 was released in early 1982. The IBM PC AT, which used it, was released in late 1984.</blockquote>
<p></p>
This is the reason why we still have a BIOS on PC architecture in 2024, to be "back-compatible" with a design from 1981 as powerful as a modern $5-priced college "scientific" calculator made in China. Which is NOT the funniest part of the story, obviously. <img class='emoji wbsketch' src='../img/emoji/wink.png'>
<p></p>
Fujitsu developed a 0-Watt ATX solution which is included into Esprimo P910 E85+ but has not provided a BIOS update for that model since 2014 and it lacks "Above 4GB decoding" to leverage PCIe 64-bit addressing. Saving energy is green but what about EoSL?
<p></p>
<blockquote>The system model in question has reached EoSL (End of Support Life) status since 2021. Hence all available support and information regarding this model beyond what is provided in the FTS Support site for this model, is no longer available. &mdash; Specialisti Fujitsu di 2nd Level.</blockquote>
<p></p>
Please notice that the last BIOS release for the P910 E85+ model is dated back in 2014, seven years before the EoSL. It is bold from their side to provide such a kind of answer! 
<p></p>
Especially because the Nvidia Tesla K80 was designed for the workstation and data-center markets, which fits perfectly in the definition of Fujitsu P910 platform: a workstation.
<p></p>
<blockquote>The Tesla K80 was a professional graphics card by NVIDIA, launched on November 17th, 2014.</blockquote>
<p></p>
Despite this, and despite not being the only 4GB+ PCIe 3.0 device on the market at that time, seven years - let me underline this number saying 2500+ days - have passed away without someone addressing this limitation which is not even publicised into the product specifications. We have to discover it by ourselves!
<p></p>
Are we sharing the same feeling about putting an end to the BIOS-as-FW paradigm?
<p></p>
<br><hr><br>
<p></p>
<div class='center'>
<H2 id="work-in-progress">WORK IN PROGRESS</H2>
</div>
<p></p>
<br><hr><br>
<div class="pagebreak"></div>
<p></p>
<H2 id="pcie-30-gpu-cards">PCIe 3.0 GPU cards</H2>
<p></p>
All the GPU cards listed below are
<p></p>
<li>double-slot width form factor, unless otherwise specified;</li>
<li>PCIe 3.0 16x, apart the Tesla K20c/m/s for which 2.0 is fine, also;</li>
<li>primarily designed for data center use, apart from those marked for PC use;</li>
<li>within a 250W maximum power consumption, apart dual-GPU models at 300W;</li>
<li>those cards consuming over 75W require an auxiliary power cable.</li>
<p></p>
All the GPU cards listed below have
<p></p>
<li>more than 4GB of on board RAM , require "Above 4GB Decoding" support by mobo/BIOS;</li>
<li>GDDR5 bandwidth range is 190-350 GB/s, dual-GPU aggregate range is 320-480 GB/s;</li>
<li>GDDR6 bandwidth range is 320-450 GB/s. HBM2 bandwidth range is 450-900 GB/s.</li>
<p></p>
As per rules of thumb:
<p></p>
<li>power cables have a standard 11A limit per line, each 12V line takes 2 pins for 132W max;</li>
<li>each power cable line is usually limited to 50% of its nominal current due to adapters use;</li>
<li>dual-GPU cards' 8-pin CPU cable powered by 4-pin CPU adapter is exceeding nominal values;</li>
<li>nominal values of power wires are intended for constant and sustained power load (TDP);</li>
<li>the GPU card TDP is 85% c.a. of the max power consumption, 75% for the dual-GPU cards.</li>
<p></p>
For local AI workloads, among the listed GPU cards:
<p></p>
<li>top models: Quadro RTX 8000, Tesla V100 32GB or Titan V 32GB, 2x Tesla T4/G;</li>
<li>resourceful: Quadro RTX 6000, Titan RTX, Tesla K80;</li>
<li>reference level: 2048 CUDA cores with 12GB of RAM;</li>
<li>entry level: 1280 CUDA cores with 8GB of RAM;</li>
<li>essentials: CUDA 3.7 on PCIe 3.0 x16.</li>
<p></p>
This list may contain inaccuracies. Always rely on official manufacturer documentation before making any purchasing or configuration decisions.
<p></p>
<div class='center'><table id='table-001'><tr><th> model </th><th> arch. </th><th> GPU </th><th> CUDA </th><th> cores </th><th> RAM </th><th> use </th><th> W-max</th><th> alim.</th><th>size</th></tr>
<tr class='trline'><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td class='td1stcol'> RTX 2060 </td><td> Turing </td><td> TU106 </td><td> 7.5 </td><td> 1920 </td><td> 6 GB GDDR6 </td><td> PC </td><td> 160W </td><td> 8p </td><td></td></tr>
<tr><td class='td1stcol'> RTX 2060 12GB </td><td> Turing </td><td> TU106 </td><td> 7.5 </td><td> 2176 </td><td> 12GB GDDR6 </td><td> PC </td><td> 184W </td><td> 8p </td><td></td></tr>
<tr><td class='td1stcol'> Quadro RTX 2070 </td><td> Turing </td><td> TU106 </td><td> 7.5 </td><td> 2304 </td><td> 8 GB GDDR6 </td><td> PC </td><td> 175W </td><td> 8p </td><td></td></tr>
<tr><td class='td1stcol'> Quadro RTX 2070S </td><td> Turing </td><td> TU104 </td><td> 7.5 </td><td> 2560 </td><td> 8 GB GDDR6 </td><td> PC </td><td> 215W </td><td> 6+8p </td><td></td></tr>
<tr><td class='td1stcol'> Quadro RTX 2080 </td><td> Turing </td><td> TU104 </td><td> 7.5 </td><td> 2944 </td><td> 8 GB GDDR6 </td><td> PC </td><td> 215W </td><td> 6+8p </td><td></td></tr>
<tr><td class='td1stcol'> Quadro RTX 4000 </td><td> Turing </td><td> TU104 </td><td> 7.5 </td><td> 2304 </td><td> 8 GB GDDR6 </td><td> PC </td><td> 160W </td><td> 8p </td><td> 1x </td></tr>
<tr><td class='td1stcol'> Quadro RTX 5000 </td><td> Turing </td><td> TU104 </td><td> 7.5 </td><td> 3072 </td><td> 16GB GDDR6 </td><td> PC </td><td> 230W </td><td> 6+8p </td><td></td></tr>
<tr><td class='td1stcol'> Tesla T4/G </td><td> Turing </td><td> TU104 </td><td> 7.5 </td><td> 2560 </td><td> 16GB GDDR6 </td><td></td><td> 75 W </td><td></td><td> 1x </td></tr>
<tr><td class='td1stcol'> CMP 50HX </td><td> Turing </td><td> TU102 </td><td> 7.5 </td><td> 3584 </td><td> 10GB GDDR6 </td><td></td><td> 250W </td><td> 2x8p </td><td></td></tr>
<tr><td class='td1stcol'> RTX 2080 Ti </td><td> Turing </td><td> TU102 </td><td> 7.5 </td><td> 4352 </td><td> 11GB GDDR6 </td><td> PC </td><td> 250W </td><td> 6+8p </td><td></td></tr>
<tr><td class='td1stcol'> RTX 2080 Ti 12 GB </td><td> Turing </td><td> TU102 </td><td> 7.5 </td><td> 4608 </td><td> 12GB GDDR6 </td><td> PC </td><td> 260W </td><td> 6+8p </td><td></td></tr>
<tr><td class='td1stcol'> Tesla T10 16 GB </td><td> Turing </td><td> TU102 </td><td> 7.5 </td><td> 3072 </td><td> 16GB GDDR6 </td><td></td><td> 150W </td><td> 1x8p </td><td></td></tr>
<tr><td class='td1stcol'> Tesla T40 24 GB </td><td> Turing </td><td> TU102 </td><td> 7.5 </td><td> 4608 </td><td> 24GB GDDR6 </td><td></td><td> 260W </td><td> 6+8p </td><td></td></tr>
<tr><td class='td1stcol'> Titan RTX </td><td> Turing </td><td> TU102 </td><td> 7.5 </td><td> 4608 </td><td> 24GB GDDR6 </td><td> PC </td><td> 280W </td><td> 2x8p </td><td></td></tr>
<tr><td class='td1stcol'> Quadro RTX 6000 </td><td> Turing </td><td> TU102 </td><td> 7.5 </td><td> 4608 </td><td> 24GB GDDR6 </td><td> PC </td><td> 260W </td><td> 6+8p </td><td></td></tr>
<tr><td class='td1stcol'> Quadro RTX 8000 </td><td> Turing </td><td> TU102 </td><td> 7.5 </td><td> 4608 </td><td> 48GB GDDR6 </td><td> PC </td><td> 260W </td><td> 6+8p </td><td></td></tr>
<tr><td class='td1stcol'> Titan V </td><td> Volta </td><td> GV100 </td><td> 7.0 </td><td> 5120 </td><td> 12GB HBM2 </td><td> PC </td><td> 250W </td><td> 6+8p </td><td></td></tr>
<tr><td class='td1stcol'> Titan V 32GB </td><td> Volta </td><td> GV100 </td><td> 7.0 </td><td> 5120 </td><td> 32GB HBM2 </td><td> PC </td><td> 250W </td><td> 6+8p </td><td></td></tr>
<tr><td class='td1stcol'> Tesla V100 </td><td> Volta </td><td> GV100 </td><td> 7.0 </td><td> 5120 </td><td> 16GB HBM2 </td><td></td><td> 250W </td><td> 2x8p </td><td></td></tr>
<tr><td class='td1stcol'> Tesla V100 32GB </td><td> Volta </td><td> GV100 </td><td> 7.0 </td><td> 5120 </td><td> 32GB HBM2 </td><td></td><td> 250W </td><td> 2x8p </td><td></td></tr>
<tr><td class='td1stcol'> Quadro GP100 </td><td> Pascal </td><td> GP100 </td><td> 6.0 </td><td> 3584 </td><td> 16GB HBM2 </td><td> PC </td><td> 235W </td><td> 8p </td><td></td></tr>
<tr><td class='td1stcol'> Tesla P100 </td><td> Pascal </td><td> GP100 </td><td> 6.0 </td><td> 3584 </td><td> 12GB HBM2 </td><td></td><td> 250W </td><td> 8p </td><td></td></tr>
<tr><td class='td1stcol'> Tesla P100 16GB </td><td> Pascal </td><td> GP100 </td><td> 6.0 </td><td> 3584 </td><td> 16GB HBM2 </td><td></td><td> 250W </td><td> 8p </td><td></td></tr>
<tr><td class='td1stcol'> Tesla P40 </td><td> Pascal </td><td> GP102 </td><td> 6.1 </td><td> 3840 </td><td> 24GB GDDR5 </td><td></td><td> 250W </td><td> 8p </td><td></td></tr>
<tr><td class='td1stcol'> GTX 1060 </td><td> Pascal </td><td> GP106 </td><td> 6.1 </td><td> 1280 </td><td> 8 GB GDDR5 </td><td> PC </td><td> 120W </td><td> 6p </td><td></td></tr>
<tr><td class='td1stcol'> GTX 1070 </td><td> Pascal </td><td> GP104 </td><td> 6.1 </td><td> 1920 </td><td> 8 GB GDDR5 </td><td> PC </td><td> 150W </td><td> 8p </td><td></td></tr>
<tr><td class='td1stcol'> GTX 1080 </td><td> Pascal </td><td> GP104 </td><td> 6.1 </td><td> 2560 </td><td> 8 GB GDDR5X </td><td> PC </td><td> 180W </td><td> 8p </td><td></td></tr>
<tr><td class='td1stcol'> Quadro P4000 </td><td> Pascal </td><td> GP104 </td><td> 6.1 </td><td> 1792 </td><td> 8 GB GDDR5 </td><td> PC </td><td> 105W </td><td> 6p </td><td> 1x </td></tr>
<tr><td class='td1stcol'> Quadro P5000 </td><td> Pascal </td><td> GP104 </td><td> 6.1 </td><td> 2560 </td><td> 16GB GDDR5 </td><td> PC </td><td> 180W </td><td> 8p </td><td></td></tr>
<tr><td class='td1stcol'> Tesla P4 </td><td> Pascal </td><td> GP104 </td><td> 6.1 </td><td> 2560 </td><td> 8 GB GDDR5 </td><td></td><td> 75 W </td><td></td><td> 1x </td></tr>
<tr><td class='td1stcol'> Quadro M4000 </td><td> Maxwell2 </td><td> GM204 </td><td> 5.2 </td><td> 1664 </td><td> 8 GB GDDR5 </td><td> PC </td><td> 120W </td><td> 6p </td><td> 1x </td></tr>
<tr><td class='td1stcol'> Quadro M5000 </td><td> Maxwell2 </td><td> GM204 </td><td> 5.2 </td><td> 2048 </td><td> 8 GB GDDR5 </td><td> PC </td><td> 150W </td><td> 6p </td><td></td></tr>
<tr><td class='td1stcol'> Tesla M60 </td><td> Maxwell2 </td><td> 2x GM204 </td><td> 5.2 </td><td> 2x 2048 </td><td> 2x 8GB GDDR5 </td><td></td><td> 300W </td><td> 8p </td><td></td></tr>
<tr><td class='td1stcol'> GTX 980 Ti </td><td> Maxwell2 </td><td> GM200 </td><td> 5.2 </td><td> 2816 </td><td> 6 GB GDDR5 </td><td> PC </td><td> 250W </td><td> 6+8p </td><td></td></tr>
<tr><td class='td1stcol'> GTX Titan X </td><td> Maxwell2 </td><td> GM200 </td><td> 5.2 </td><td> 3072 </td><td> 12GB GDDR5 </td><td> PC </td><td> 250W </td><td> 6+8p </td><td></td></tr>
<tr><td class='td1stcol'> Quadro M6000 24GB </td><td> Maxwell2 </td><td> GM200 </td><td> 5.2 </td><td> 3072 </td><td> 24GB GDDR5 </td><td> PC </td><td> 250W </td><td> 8p </td><td></td></tr>
<tr><td class='td1stcol'> Quadro M6000 </td><td> Maxwell2 </td><td> GM200 </td><td> 5.2 </td><td> 3072 </td><td> 12GB GDDR5 </td><td> PC </td><td> 250W </td><td> 8p </td><td></td></tr>
<tr><td class='td1stcol'> Tesla M40 24GB </td><td> Maxwell2 </td><td> GM200 </td><td> 5.2 </td><td> 3072 </td><td> 24GB GDDR5 </td><td></td><td> 250W </td><td> 8p </td><td></td></tr>
<tr><td class='td1stcol'> Tesla M40 </td><td> Maxwell2 </td><td> GM200 </td><td> 5.2 </td><td> 3072 </td><td> 12GB GDDR5 </td><td></td><td> 250W </td><td> 8p </td><td></td></tr>
<tr class='trline'><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td class='td1stcol'> Tesla K80 </td><td> Kepler </td><td> 2x GK210 </td><td> 3.7 </td><td> 2x 2496 </td><td> 2x 12GB GDDR5 </td><td></td><td> 300W </td><td> 8p </td><td></td></tr>
<tr class='trline'><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td class='td1stcol'> Tesla K40c </td><td> Kepler </td><td> GK180 </td><td> 3.5 </td><td> 2880 </td><td> 12GB GDDR5 </td><td></td><td> 245W </td><td> 6+8p </td><td></td></tr>
<tr><td class='td1stcol'> Quadro K6000 SDI </td><td> Kepler </td><td> GK110 </td><td> 3.5 </td><td> 2880 </td><td> 12GB GDDR5 </td><td> PC </td><td> 239W </td><td> 2x6p </td><td></td></tr>
<tr><td class='td1stcol'> GTX Titan </td><td> Kepler </td><td> GK110 </td><td> 3.5 </td><td> 2880 </td><td> 6 GB GDDR5 </td><td> PC </td><td> 250W </td><td> 6+8p </td><td></td></tr>
<tr><td class='td1stcol'> Tesla K20X/Xm </td><td> Kepler </td><td> GK110 </td><td> 3.5 </td><td> 2688 </td><td> 6 GB GDDR5 </td><td></td><td> 235W </td><td> 6+8p </td><td></td></tr>
<tr><td class='td1stcol'> Tesla K20c/m/s </td><td> Kepler </td><td> GK110 </td><td> 3.5 </td><td> 2496 </td><td> 5 GB GDDR5 </td><td></td><td> 225W </td><td> 6+8p </td><td></td></tr>
</table>
</div><p></p>
The CUDA support for compute capability 3.5 can be obtained via third party support for PyTorch, also.
<p></p>
<H4>Data sources</H4>
<p></p>
<li><a href="https://www.techpowerup.com/gpu-specs" target='_blank' rel='noopener noreferrer'>www.techpowerup.com</a></li>
<li><a href="https://developer.nvidia.com/cuda-gpus" target='_blank' rel='noopener noreferrer'>developer.nvidia.com</a></li>
<p></p>
<br>
<p></p>
<H2 id="external-resources">External resources</H2>
<p></p>
<li><a href="https://blog.nelsonliu.me/2020/10/13/newer-pytorch-binaries-for-older-gpus" target='_blank' rel='noopener noreferrer'>Newer PyTorch Binaries for Older GPUs</a> (October 13, 2020)</li>
<li class='li2in'><a href="https://github.com/nelson-liu/pytorch-manylinux-binaries/releases" target='_blank' rel='noopener noreferrer'>Nvidia K40 GPUs PyTorch v1.13.1</a></li>
<p></p>
<li><a href="https://www.techpowerup.com/vgabios" target='_blank' rel='noopener noreferrer'>techpowerup vgabios</a></li>
<p></p>
<H2 id="share-alike">Share alike</H2>
<p></p>
<p>&copy; 2025, <b>Roberto A. Foglietta</b> &lt;roberto.foglietta<span>&commat;</span>gmail.com&gt;, <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target='_blank' rel='noopener noreferrer'>CC BY-NC-ND 4.0</a></p>
<p></p>
</div>
<div id='date-legenda' align='center' translate='no'><sub><hr></sub><sub><b>date legenda</b>: &#x2776; first draft publishing date or &#x2777; creation date in git, otherwise &#x2778; html creation page date. <u>&mapstoup;<a href='#' class='toplink' translate='no'>top</a>&mapstoup;</u></sub></div>
<br class='pagebreak'>
    </body>
</html>
