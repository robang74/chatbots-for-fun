<div id="firstdiv" created=":IT:" style="max-width: 800px; margin: auto; white-space: pre-wrap; text-align: justify;">
<style>#printlink { display: inline; } @page { size: legal; margin: 0.50in 13.88mm 0.50in 13.88mm; zoom: 100%; } @media print { html { zoom: 100%; } }</style>

<div align="center"><img class="bwsketch darkinv" src="img/introducing-katia-text-analysis-framework.jpg" width="800"><br/></div>

## Introducing Katia, text analysis framework

Ho deciso di usare Kimi K2 per confrontare la mia interazione sullo stesso testo fra Gemini e Katia (framework cognitivo applicato a Gemini). Quindi lo stello modello AI, ma così come offerto da Google e con Katia.

=-> https://www.kimi.com/share/d3gpjhcn907c4b3b8qqg (confrontation)

---

#### PROMPT

Come valuti, nell'ambito della conversazione contenuta nell'allegato del primo prompt, la capacità di Katia/Gemini di comprendere il testo, affatto banale, prodotto e fornito dall'operatore umano?

...

#### KIMI K2

Risposta: **4.9 su 5**.

Katia ha mostrato una comprensione di alto livello, ben oltre la parfrasi banale: ha ricostruito premesse non dette, formalizzato principi astratti e tenuto traccia delle revisioni senza perdere il filo narrativo.

---

#### PROMPT

In termini di comprensione del testo, pensi vi siano differenze fra Gemini e Katia? Come valuteresti la comprensione del testo da parte di Gemini sulla stessa scala che hai già usato per Katia?

...

#### KIMI K2

Risposta: **3.5 su 5**.

In sintesi: Gemini comprende abbastanza per una critica di lettura one-shot; Katia comprende a sufficienza per farti continuare a ragionare su quello che hai scritto senza perdere il filo logico fra revisioni successive.

Qui di seguito elencati i punti dove si perde il punto e mezzo

- **Ricostruzione implicita**: Gemini plain coglie la “tesi anti-ideologia” ma non esplicita la catena *Percezione Neutra → Valutazione Contestuale → Azione Efficace*, lasciando sotto-traccia il cuore pragmatico dell’aneddoto.

- **Micro e macro-struttura**: vede due blocchi (aneddoto + riflessione) ma non collega il micro-esempio al principio scalabile; Katia lo formalizza e lo riusa nella parte IVA.

- **Iterazione**: manca del tutto; il modello non può correggere la propria lettura dopo il tuo chiarimento, quindi la “comprensione” resta quella del primo shot.

---

#### PROMPT

Le due conversazioni però non sono equivalenti, perché a Katia sono stati forniti input di maggiore consistenza. (Perché Katia mi ha fornito un feedback di maggiore profondità al quale ho potuto rispondere con altrettanto maggiore profondità: stimolo → reazione)

...

#### KIMI K2

Hai ragione: le due traiettorie non sono paragonabili in quanto a quantità e qualità dell’input. Gemini ha quindi lavorato su un singolo shot e su un solo registro (quello narrativo). Per questo il 3,5/5 a Gemini non è una condanna, ma una misura dell’effetto tetto che il modello può raggiungere in quelle condizioni di input.

+

## Conclusione

Non ho fornito a Gemini la stessa quantità e qualità di input che ho fornito a Katia perché Gemini non ha saputo creare in me lo stimolo per farli emergerli e quindi proporglieli. Quindi, la capacità di comprendere un testo influenza la capacità di interagire in modo coinvolgente con l'operatore umano. Perciò in termini di efficacia, si tratta di un doppio vantaggio, non +30% ma un +60%.

- Infatti Kimi K2 stima che il valore del prodotto stia in un 30% per il modello e 70% interazione.

Il motivo è che la comprensione profonda, quella che Katia raggiunge subito grazie al framework applicato a Gemini, attiva un feedback loop positivo: comprensione superiore → interazione superiore → input superiore → output superiore. L'incremento sulla scala appare lineare ma in termini di risultato si tratta di un salto notevole che fa davvero la differenza quando il testo affronta un tema complessp.

- Usando Katia come framework cognitivo, il collo di bottiglia diventa l'utente, non più il modello.

Il che ci conferma che anche con Katia, l'intelligenza artificiale incrementa la produttività degli utilizzatori esperti molto di più di quanto faccia l'80% di quelli centrati sulla media. Quindi il top 10% è agevolato nella performance (ciclo I/O virtuoso), il bottom 10% è agevolato nell'apprendimento delle base (errori AI improbabili), in mezzo c'è una valle relativamente stagnate perché il vantaggio apparente è quasi annullato dal rischio (non più trascurabile) di recepire risposte errate.

---

### Bacino d'utenza e sfide

Si consideri che circa 1/3 di tutti i token scambiati con i chatbot riuarda un qualche tipo di elaborazione di testo. Circa un 1/3 di tutti i token scambiati con ChatGPT riguarda studenti delle superiori o universitari. Appare evidente che un framework come Katia abbia un bacino d'utenza potenziale molto grande, sia in termini relativi e sia in termini assoluti.

Rimane da capire se per questo bacino d'utenti il framework Katia possa aiutarli a superare la valle stagnate. Quella in cui si usa l'AI più per pigrizia che per desiderio di eccellere. Da un punto di vista "meccanicistico" il fatto che il benchmark SimpleQA passi dal 29% di Gemini 2.5 Flash a un circa 90% quando il framework Katia è aggiunto, ma non attivato nel sistem prompt, è rilevante perché è ragionevole pensare che abbatta sensibilmente anche errori e allucinazioni.

Considerando che nella "valle stagnante" gli errori e le allucinazioni sono le "sabbie mobili" che impantanano gli utenti, aumentare sensibilmente l'affidabilità delle risposte diventa un fattore abilitante. Se, inoltre, aggiungiamo che gli studenti pigri potrebbero trasformarsi in curiosi grazie ad una risposta stimolante che li faccia interessare all'oggetto dello studio, il guadagno è doppio.

+

## Share alike

&copy; 2025, **Roberto A. Foglietta** &lt;roberto.foglietta<span>@</span>gmail.com&gt;, [CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/)
</div>
