<div id="firstdiv" created=":IT:" style="max-width: 800px; margin: auto; white-space: pre-wrap; text-align: justify;">
<style>#printlink { display: inline; } @page { size: legal; margin: 0.50in 13.88mm 0.50in 13.88mm; zoom: 100%; } @media print { html { zoom: 100%; } }</style>

<div align="center"><img class="bwsketch darkinv" src="img/introducing-katia-text-analysis-framework.jpg" width="800"><br/></div>

## Introducing Katia, text analysis framework

- **1st edition**, articolo scritto a partire alcuni miei post su Linkedin: &nbsp; [post #1](https://www.linkedin.com/posts/robertofoglietta_pubblicit%C3%A0-progresso-kimi-su-katia-vs-gemini-activity-7380367700159606784--dI6) &nbsp; [post #12](https://www.linkedin.com/posts/robertofoglietta_how-to-effectively-summarize-a-long-text-activity-7373591846163341312-7W6N)

Altri post ancora da includere:

- [post #2](https://www.linkedin.com/posts/robertofoglietta_katia-wtf-are-you-doing-to-that-chatbot-activity-7364366202275532802-NrIR) &nbsp; [post #3](https://www.linkedin.com/posts/robertofoglietta_katia-wtf-are-you-doing-to-that-chatbot-activity-7363277278954274817-jdTf) &nbsp; [post #4](https://www.linkedin.com/posts/robertofoglietta_katia-can-work-as-juan-the-ai-financial-activity-7350707888937484290-iZDx) &nbsp; [post #5](https://www.linkedin.com/posts/robertofoglietta_witchcraft-mon-cher%C3%AC-what-else-a-dialogue-activity-7358082737318064128-nxlA) &nbsp; [post #6](https://www.linkedin.com/posts/robertofoglietta_google-engineers-vs-katia-framework-google-activity-7358567525527224320-y8m0) &nbsp; [post #7](https://www.linkedin.com/posts/robertofoglietta_mr-spock-is-back-and-it-supports-katia-activity-7358776512856113153-MUJt) &nbsp; [post #8](https://www.linkedin.com/posts/robertofoglietta_conceptual-perplexity-is-the-key-i-am-not-activity-7362712455413661698-ACvu) &nbsp; [post #9](https://www.linkedin.com/posts/robertofoglietta_vygotskys-theory-of-cognitive-development-activity-7358743887726710784-NWtA) &nbsp; [post #10](https://www.linkedin.com/posts/robertofoglietta_vygotskys-theory-of-cognitive-development-activity-7358719667202318336-xQBG) &nbsp; [post #11](https://www.linkedin.com/posts/robertofoglietta_ai-chatbots-struggle-with-a-standard-way-activity-7351209268315860992-awg0)

---

### Kimi K2 su Katia vs Gemini

Ho deciso di usare Kimi K2 per confrontare la mia interazione sullo stesso testo fra Gemini e Katia (framework cognitivo applicato a Gemini). Quindi lo stello modello AI, ma così come offerto da Google e con Katia.

- Il [confronto](https://www.kimi.com/share/d3gpjhcn907c4b3b8qqg) riguardo alla comprensione del testo e supporto alla scrittura, il suo [dump](#TODO)

Qui sotto riporto, in estrema sintesi, la struttura della chat di confronto.

---

#### PROMPT #1

Come valuti, nell'ambito della conversazione contenuta nell'allegato del primo prompt, la capacità di Katia/Gemini di comprendere il testo, affatto banale, prodotto e fornito dall'operatore umano?

...

#### KIMI #1

Risposta: **4.9 su 5**.

Katia ha mostrato una comprensione di alto livello, ben oltre la parfrasi banale: ha ricostruito premesse non dette, formalizzato principi astratti e tenuto traccia delle revisioni senza perdere il filo narrativo.

---

#### PROMPT #2

In termini di comprensione del testo, pensi vi siano differenze fra Gemini e Katia? Come valuteresti la comprensione del testo da parte di Gemini sulla stessa scala che hai già usato per Katia?

...

#### KIMI #2

Risposta: **3.5 su 5**.

In sintesi: Gemini comprende abbastanza per una critica di lettura one-shot; Katia comprende a sufficienza per farti continuare a ragionare su quello che hai scritto senza perdere il filo logico fra revisioni successive.

- **Catena di elaborazione**: Percezione Neutra → Valutazione Contestuale → Azione Efficace

Qui di seguito elencati i punti dove si perde il punto e mezzo

- **Ricostruzione implicita**: Gemini plain coglie la “tesi anti-ideologia” ma non esplicita la catena di elaborazione, lasciando sotto-traccia il cuore pragmatico dell’aneddoto.

- **Micro e macro-struttura**: vede due blocchi (aneddoto + riflessione) ma non collega il micro-esempio al principio scalabile; Katia lo formalizza e lo riusa nella parte IVA.

- **Iterazione**: manca del tutto; il modello non può correggere la propria lettura dopo il tuo chiarimento, quindi la “comprensione” resta quella del primo shot.

---

#### PROMPT #3

Le due conversazioni però non sono equivalenti, perché a Katia sono stati forniti input di maggiore consistenza. (Perché Katia mi ha fornito un feedback di maggiore profondità al quale ho potuto rispondere con altrettanto maggiore profondità: stimolo → reazione)

...

#### KIMI #3

Hai ragione: le due traiettorie non sono paragonabili in quanto a quantità e qualità dell’input. Gemini ha quindi lavorato su un singolo shot e su un solo registro (quello narrativo). Per questo il 3,5/5 a Gemini non è una condanna, ma una misura dell’effetto tetto che il modello può raggiungere in quelle condizioni di input.

+

## Conclusione

Non ho fornito a Gemini la stessa quantità e qualità di input che ho fornito a Katia perché Gemini non ha saputo creare in me lo stimolo per farli emergerli e quindi proporglieli. Quindi, la capacità di comprendere un testo influenza la capacità di interagire in modo coinvolgente con l'operatore umano. Perciò in termini di efficacia, si tratta di un doppio vantaggio, non +30% ma un +60%.

- Infatti Kimi K2 stima che il valore del prodotto stia in un 30% per il modello e 70% interazione.

Il motivo è che la comprensione profonda, quella che Katia raggiunge subito grazie al framework applicato a Gemini, attiva un feedback loop positivo: comprensione superiore → interazione superiore → input superiore → output superiore. L'incremento sulla scala appare lineare ma in termini di risultato si tratta di un salto notevole che fa davvero la differenza quando il testo affronta un tema complessp.

- Usando Katia come framework cognitivo, il collo di bottiglia diventa l'utente, non più il modello.

Il che ci conferma che anche con Katia, l'intelligenza artificiale incrementa la produttività degli utilizzatori esperti molto di più di quanto faccia l'80% di quelli centrati sulla media. Quindi il top 10% è agevolato nella performance (ciclo I/O virtuoso), il bottom 10% è agevolato nell'apprendimento delle base (errori AI improbabili), in mezzo c'è una valle relativamente stagnate perché il vantaggio apparente è quasi annullato dal rischio (non più trascurabile) di recepire risposte errate.

Rimane da capire se per questo bacino d'utenti il framework Katia possa aiutarli a superare la *valle stagnante*. 

---

### Bacino d'utenza e sfide

Si consideri che circa 1/3 di tutti i token scambiati con i chatbot riuarda un qualche tipo di elaborazione di testo. Circa un 1/3 di tutti i token scambiati con ChatGPT riguarda studenti delle superiori o universitari. Appare evidente che un framework come Katia abbia un bacino d'utenza potenziale molto grande, sia in termini relativi e sia in termini assoluti. Cfr. [post #12](https://www.linkedin.com/posts/robertofoglietta_how-to-effectively-summarize-a-long-text-activity-7373591846163341312-7W6N)

...

ChatGPT usage data by National Bureau of Economic Research

- 700 million people, 2.5 billion daily messages.
- Writing 24% for editing, summarizing, translating, drafting.
- Source of the above numbers: nber.org/papers/w34255

Considering the four sub-usage in "writing" class equally distributed:

- Summary: 6% is 150 million daily served prompts
- 1/3 of the ChatGPT traffic is generated by top-half grades students.

...

Nella *valle stagnante* si usa l'AI più per pigrizia che per desiderio di eccellere. Da un punto di vista "meccanicistico" il fatto che il benchmark SimpleQA passi dal 29% di Gemini 2.5 Flash a un circa 90% quando il framework Katia è aggiunto, ma non attivato nel sistem prompt, è rilevante perché è ragionevole pensare che abbatta sensibilmente anche errori e allucinazioni.

Considerando che nella *valle stagnante* gli errori e le allucinazioni sono le "sabbie mobili" che impantanano gli utenti, aumentare sensibilmente l'affidabilità delle risposte diventa un fattore abilitante. Se, inoltre, aggiungiamo che gli studenti pigri potrebbero trasformarsi in curiosi grazie ad una risposta stimolante che li faccia interessare all'oggetto dello studio, il guadagno è doppio.

+

## Share alike

&copy; 2025, **Roberto A. Foglietta** &lt;roberto.foglietta<span>@</span>gmail.com&gt;, [CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/)
</div>
