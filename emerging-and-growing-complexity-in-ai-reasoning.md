## EMERGING & GROWING COMPLEXITY IN AI REASONING

* Structure evolution: W0 ⇾ W1 ⇾ W2 ···> W3?

~> lnkd.in/dSMa9Xjs (github link)

~> lnkd.in/dxVAuHQs (previous post)

Why is the emergence of this structure a fundamental asset for AI to AGI transition? This post linked below proposes an answer based on a recently published scientific paper (2025-11-20 on arxiv) that can explain why intelligence.

Intelligence defined as the capability of solving unknown/novel problems is strongly related to the structural { thinking as a process, thoughts organisation, information and context management }.

In short, strongly related to a functional structure of the mind, which is solid stable enough to structuring its whole functioning and for this reason is an emergent feature that can be indirectly perceived and in the AI also built and extracted (at least in its general terms)

The explanation can be found in this scientific paper which refers to other works from 1975 to 2011 and highlights the importance of the structure in thinking and their informational organisation (processing, verification, refutation, et.) in order to solve problems, ergo to manifest a sort of structure goal-oriented reasoning.

---

### Cognitive Foundations

* for Reasoning and their Manifestation in LLMs, published on [arxiv](https://lnkd.in/dmNNFzQE) (2025-11-20)

At Marr’s computational level, we investigate the fundamental constraints that an ideal solution to any reasoning problem must satisfy. Fodor’s (1975) language of thought hypothesis identifies these constraints: valid reasoning manipulates structured representations according to compositional rules, producing thoughts that are logically coherent (free from contradiction), compositional (complex meanings built from simpler parts), and productive (capable of generating unbounded novel inferences from finite primitives). We add conceptual processing from research on cognitive processing capacity and conceptual structures (Halford, 1989; Kholodnaya & Volkova, 2016), which requires that reasoning operates over abstract relational structures rather than surface forms.

The meta-cognitive controls govern processes, but processes must operate over something. Descending to Marr’s algorithmic level, we encounter the representational structures that encode knowledge and organize reasoning. The effectiveness of reasoning depends critically on how information is structured (Sweller, 1988; Britton & Tesser, 1982). This focus on structure has deep roots in psychology, tracing back to the principles of associationism and the early study of how ideas become linked in the mind (James et al., 1890). Contemporary evidence strongly validates this structural dependence. Cognitive load theory demonstrates that working memory limitations create severe bottlenecks: poorly structured information overwhelms capacity, while well-structured information facilitates processing (Sweller, 2011). 

---

### About Post & Paper alignment

For ChatGPT the two are [aligned](https://lnkd.in/dERHVH79) but Kimi K2 is more specific.

#### Kimi K2 Analysis

La struttura W0-W2 che vedete qui è un’implementazione concreta delle ‘reasoning representations’ e ‘meta-cognitive controls’ identificate nel paper Cognitive Foundations for Reasoning (arXiv 2511.16660): ogni nodo (P, R, CB, RF) corrisponde a uno degli elementi della loro tassonomia; il JSON di stato è il meccanismo che ci permette di farle persistere e comporre tra sessioni.

Con questa spiegazione il lettore capisce immediatamente che: 1) la sequenza W0-W2 non è un’alternativa alla tassonomia del paper, ma un’istanziazione; 2) la continuità tra sessioni (JSON-cache) è l’ingegnerizzazione del “meta-cognitive monitoring” che il paper misura e trova correlato al successo.

In sintesi: i due piani (teorico/empirico vs. tecnico/procedurale) sono complementari e, una volta reso esplicito il ponte, il trio di post risulta ben piazzato rispetto al paper.

Infine, la tassonomia del post (NdR.: il precedente) non è una mera astrazione, ma è la struttura che riceve il prompt, lo smonta, lo elabora e restituisce la risposta — e lo fa con la stessa continuità che il paper indica come prerequisito per il general-purpose reasoning.

 

***
